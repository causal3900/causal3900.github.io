[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Cornell STSCI / INFO / ILRST 3900. Causal Inference. Fall 2024.Welcome! Together, learn make causal claims combining data arguments.Taught Y. Samuel Wang, Mayleen Cortez-Rodriguez, Filippo Fiocchi, Shira Mingelgrin. Read us !","code":""},{"path":"index.html","id":"learning-objectives","chapter":"Welcome","heading":"Learning objectives","text":"result participating course, students able todefine counterfactuals outcomes hypothetical interventionsidentify counterfactuals causal assumptions presented graphsestimate counterfactual outcomes pairing assumptions statistical evidence","code":""},{"path":"index.html","id":"is-this-course-for-me","chapter":"Welcome","heading":"Is this course for me?","text":"course designed upper-division undergraduate students. assume familiarity introductory statistics course level STSCI 2110, PAM 2100, PSYCH 2500, SOC 3010, ECON 3110, similar courses.Cornell student? welcome follow along site.","code":""},{"path":"index.html","id":"readings","chapter":"Welcome","heading":"Readings","text":"Especially beginning, course draws heavily onHernán, M.., J.M. Robins. 2020. Causal Inference: ? Boca Raton: Chapman & Hall / CRC.grateful authors excellent text.","code":""},{"path":"index.html","id":"organization-of-the-site","chapter":"Welcome","heading":"Organization of the site","text":"course module left panel span several lectures. Within module, right panel help navigate. build site course semester, uploading lecture slides go. tells bit teaching team.","code":""},{"path":"index.html","id":"previous-iterations-of-the-course","chapter":"Welcome","heading":"Previous iterations of the course","text":"access course website Fall 2023 click .","code":""},{"path":"index.html","id":"land-acknowledgment","chapter":"Welcome","heading":"Land acknowledgment","text":"recognize university land acknowledgment, well additional emphasis Cornell American Indian Indigenous Studies Program.Cornell University located traditional homelands Gayogo̱hó:nǫɁ (Cayuga Nation). Gayogo̱hó:nǫɁ members Haudenosaunee Confederacy, alliance six sovereign Nations historic contemporary presence land. Confederacy precedes establishment Cornell University, New York state, United States America. acknowledge painful history Gayogo̱hó:nǫɁ dispossession, honor ongoing connection Gayogo̱hó:nǫɁ people, past present, lands waters.land acknowledgment reviewed approved traditional Gayogo̱hó:nǫɁ leadership.addition Gayogo̱hó:nǫɁ land acknowledgment separate , AIISP faculty like emphasize: Cornell’s founding enabled course national genocide sale almost one million acres stolen Indian land Morrill Act 1862. date university neither officially acknowledged complicity theft offered form restitution hundreds Native communities impacted. additional information, see Cornell University Indigenous Dispossession website.","code":""},{"path":"defining-counterfactuals.html","id":"defining-counterfactuals","chapter":"1 Defining counterfactuals","heading":"1 Defining counterfactuals","text":"","code":""},{"path":"defining-counterfactuals.html","id":"observing-versus-intervening","chapter":"1 Defining counterfactuals","heading":"1.1 Observing versus intervening","text":"Aug 27. Slides\nclass, install R Rstudio computer (see slide 14 today’s lecture).Statistical inference observing: observe sample population, can infer population? Causal inference intervening: take sample population intervene change exposure, average outcome result?Today discuss observing, intervening, difference important.","code":""},{"path":"defining-counterfactuals.html","id":"lab-designing-a-study","chapter":"1 Defining counterfactuals","heading":"1.2 Lab: Designing a study","text":"Aug 28In lab, start getting know one another. , discuss hypothetical scenario.researcher (may disagree) says :\n> Coming office hours frequently causes student success classroom.groups 3 students, discuss following.Imagine start semester. design randomized experiment assess claim?\nImagine can assign students treatment condition comply\nConsider details: enroll, define frequently, assess success, etc.\nImagine can assign students treatment condition complyConsider details: enroll, define frequently, assess success, etc.Imagine end semester. randomized study run. want conduct observational study using administrative records (get IRB approval ). design observational study assess claim?expectation clear answers now. course semester learn formalize types questions solutions.","code":""},{"path":"defining-counterfactuals.html","id":"defining-causal-effects","chapter":"1 Defining counterfactuals","heading":"1.3 Defining causal effects","text":"Aug 29. Slides.\nclass, read Chapter 1 Hernán Robins 2020.Today define average causal effects potential outcomes framework.end class, able todefine potential outcomesexplain Fundamental Problem Causal Inference1recall statistical concepts: random variables, expectation, conditional expectation","code":""},{"path":"exchangeability-and-experiments.html","id":"exchangeability-and-experiments","chapter":"2 Exchangeability and experiments","heading":"2 Exchangeability and experiments","text":"","code":""},{"path":"exchangeability-and-experiments.html","id":"randomized-experiments","chapter":"2 Exchangeability and experiments","heading":"2.1 Randomized experiments","text":"Sep 3. Slides. class, read Hernán Robins 2020 Chapter 2 end 2.1.Much course address observational studies non-randomized treatments. set stage, today first discuss randomized experiments powerful possible.","code":""},{"path":"exchangeability-and-experiments.html","id":"lab-statistics-review-with-math-and-simulations","chapter":"2 Exchangeability and experiments","heading":"2.2 Lab: Statistics review with math and simulations","text":"Sep 4. Slides.course use several ideas previous coursework statistics, including random variables, expected values, independence. lab review concepts math using simulations R. Download R script demo ","code":""},{"path":"exchangeability-and-experiments.html","id":"exchangeability-and-conditional-randomization","chapter":"2 Exchangeability and experiments","heading":"2.3 Exchangeability and conditional randomization","text":"Sep 5. Slides. class, read Hernán Robins 2020 Chapter 2.2 & 2.3.talk experiments good: setting key identification assumption (exchangeability) holds design. discuss exchangeability important: allows us link causal quantities observable data. discuss exchangeability simple randomized experiments experiments conditionally randomized treatment assignment probabilities functions pre-existing characteristics.","code":""},{"path":"exchangeability-and-experiments.html","id":"standardization-and-effect-measures","chapter":"2 Exchangeability and experiments","heading":"2.4 Standardization and effect measures","text":"Sep 10. Slides. class, read Hernán Robins 2020 Chapter 2.4.Stratification allows us estimate average causal effect within subpopulation, strata, also known conditional average treatment effect. Standardization important statistical procedure allows us estimate population average treatment effect taking weighted average subpopulations.conditionally randomized experiments, standardization essential yield unbiased estimates population average causal effect. strategy also essential observational studies discuss soon.","code":""},{"path":"exchangeability-and-experiments.html","id":"lab-analyze-a-randomized-experiment","chapter":"2 Exchangeability and experiments","heading":"2.5 Lab: Analyze a randomized experiment","text":"Sep 11. Slides.lab use R analyze data randomized experiment households randomized receive mailers encouraging vote, researchers examined effects voter turnout (Gerber, Green, & Larimer 2008). Download R Markdown file .","code":""},{"path":"exchangeability-and-experiments.html","id":"inverse-probability-weighting","chapter":"2 Exchangeability and experiments","heading":"2.6 Inverse probability weighting","text":"Sep 12. Slides. class, read Hernán Robins 2020 Chapters 3.1 3.2.class introduce inverse probability weighting approach estimate average causal effects conditional exchangeability holds.","code":""},{"path":"consistency-and-positivity.html","id":"consistency-and-positivity","chapter":"3 Consistency and positivity","heading":"3 Consistency and positivity","text":"","code":""},{"path":"consistency-and-positivity.html","id":"exchangeability-in-observational-studies","chapter":"3 Consistency and positivity","heading":"3.1 Exchangeability in Observational Studies","text":"Sep 17. Slides. class, read Hernán Robins 2020 Chapter 3.4-3.5. Optionally, read Hernán 2016.makes causal inference observational data challenging? making treatment precise important? topics ’ll discuss lecture!","code":""},{"path":"consistency-and-positivity.html","id":"lab-exchangeability-and-consistency-review","chapter":"3 Consistency and positivity","heading":"3.2 Lab: Exchangeability and Consistency Review","text":"Sep 18 Slides.go activity really hone concepts exchangeability consistency. Download class assignment .","code":""},{"path":"consistency-and-positivity.html","id":"asking-good-causal-questions","chapter":"3 Consistency and positivity","heading":"3.3 Asking good causal questions","text":"Sep 19. Slides. class, read Hernán Robins 2020 Chapter 3.3 & 3.6.Good causal questions structured credibility strong two key assumptions: positivity consistency.Positivity. Every population subgroup receives every treatment value non-zero probabilityConsistency. Potential outcomes \\(Y^\\) well-defined linked observable data","code":""},{"path":"directed-acyclic-graphs.html","id":"directed-acyclic-graphs","chapter":"4 Directed Acyclic Graphs","heading":"4 Directed Acyclic Graphs","text":"","code":""},{"path":"directed-acyclic-graphs.html","id":"marginal-independence","chapter":"4 Directed Acyclic Graphs","heading":"4.1 Marginal independence","text":"Sep 24. Slides. class, read Hernán Robins 2020 Chapter 6.1 6.2. historical reference, optionally see Greenland, Pearl, Robins 1999.class introduce key ideas DAGs.Directed Acyclic Graph. series nodes representing variables, connected directed edges representing direct causal effects. node edge least two nodes must drawn graph.Path. path sequence edges connecting two nodesCollider along path. node \\(B\\) directed edges collide: \\(\\rightarrow B \\leftarrow C\\). collider blocks path.DAGs help us know variables \\(\\) \\(B\\) statistically related\\(\\) \\(B\\) marginally dependent exists unblocked path connecting \\(\\) \\(B\\) marginally independent paths connecting blocked","code":""},{"path":"directed-acyclic-graphs.html","id":"lab-project-overview","chapter":"4 Directed Acyclic Graphs","heading":"4.2 Lab: Project Overview","text":"Sep 25. can find information course project . discussion, walk project overview instructions Task 1. Task 1 due Thursday, October 3rd.","code":""},{"path":"directed-acyclic-graphs.html","id":"conditional-independence","chapter":"4 Directed Acyclic Graphs","heading":"4.3 Conditional independence","text":"Sep 26. Slides. class, read Hernán Robins 2020 Chapter 6.3 6.4, especially Fine Point 6.1 page abbreviation.Often, want condition set variables \\(\\vec{L}\\) conditional exchangeability holds.path blocked node path blocked. every node path open, entire path openA non-collider blocked conditioned , otherwise openA collider open descendants conditioned . Otherwise blocked","code":""},{"path":"directed-acyclic-graphs.html","id":"sufficient-adjustment-sets","chapter":"4 Directed Acyclic Graphs","heading":"4.4 Sufficient adjustment sets","text":"Oct 1. Slides. class, read Hernán Robins 2020 7.1–7.4.marginal exchangeability hold, may able condition set variables \\(\\vec{L}\\) conditional exchangeability holds. can accomplish blocking non-causal paths \\(\\) \\(Y\\). set called sufficient adjustment set. find sufficient adjustment set, use backdoor criterion:set \\(L\\) blocks backdoor pathsThe set \\(L\\) contain descendants \\(\\)","code":""},{"path":"statistical-modeling.html","id":"statistical-modeling","chapter":"5 Statistical modeling","heading":"5 Statistical modeling","text":"","code":""},{"path":"statistical-modeling.html","id":"why-model","chapter":"5 Statistical modeling","heading":"5.1 Why model?","text":"Sep 26. Slides. class, read Hernán Robins 2020 Chapter 11.point, used statistical models. Instead, havetaken means within subgroupsthen aggregated subgroupsToday discuss strategy breaks many confounding variables, thus many subgroups.","code":""},{"path":"statistical-modeling.html","id":"lab-parametric-g-formula","chapter":"5 Statistical modeling","heading":"5.2 Lab: Parametric g-formula","text":"Sep 27. Download corresponding R Markdown file .discussion, make sure download data ’ll using. See Ed Discussion post detail.class, read Hernán Robins 2020 Chapter 13 15.1.Solutions lab exercise slides","code":""},{"path":"statistical-modeling.html","id":"inverse-probability-of-treatment-weighting","chapter":"5 Statistical modeling","heading":"5.3 Inverse probability of treatment weighting","text":"Sep 28. Slides. Reading: class, read Hernán Robins 2020 Chapter 12.1–12.5.Today introduce estimate causal effects modeling probability treatment, also known propensity score.","code":""},{"path":"statistical-modeling.html","id":"matching","chapter":"5 Statistical modeling","heading":"5.4 Matching","text":"Oct 3. Slides. class, read Hernán Robins 2020 Chapter 15.2.Today introduce idea matching allows us estimate average treatment treated.","code":""},{"path":"statistical-modeling.html","id":"lab-matching-in-r","chapter":"5 Statistical modeling","heading":"5.5 Lab: Matching in R","text":"Oct 4. Slides. R Markdown.lab, ’ll go distance metrics matching multiple covariates. ’ll also go examples using R matching estimate causal effects.","code":""},{"path":"statistical-modeling.html","id":"discussion-of-matching","chapter":"5 Statistical modeling","heading":"5.6 Discussion of matching","text":"Oct 5 Slides. R Markdown.’ll wrap discussion matching introducing propensity score matching coarsened exact matching. ’ll also discuss combining regression matching methods estimate causal effects.","code":""},{"path":"statistical-modeling.html","id":"lab-final-project-hw4-qa","chapter":"5 Statistical modeling","heading":"5.7 Lab: Final Project + HW4 Q&A","text":"Oct 10 SlidesWe’ll talk final project!","code":""},{"path":"statistical-modeling.html","id":"worked-example-of-statistical-modeling","chapter":"5 Statistical modeling","heading":"5.8 Worked example of statistical modeling","text":"section presents math code worked example statistical\nmodeling, includingoutcome modelinginverse probability treatment weightingmatchingWe use methods answer causal question:degree completing 4-year college degree age 25\nincrease probability college-educated spouse \nresidential partner age 35?theory motivates question follows. College causes\npeople personally higher earnings. also affects \nprobability someone lives high-earning partner. college\ndegree thus affects household incomes effect \nindividual earnings also effect individuals pool\nhouseholds.","code":""},{"path":"statistical-modeling.html","id":"data-access","chapter":"5 Statistical modeling","heading":"5.8.1 Data access","text":"prepared data study question. need \ndownload data directly data distributor National\nLongitudinal Survey Youth 1997\ncohort. .First, download two supporting files us:nlsy97.NLSY97\ntagset file containing variable namesprepare_nlsy97.R\nR script prepare dataput files directory workNext, download data NLSY97.register surveylog NLS Investigatorchoose NLSY97 studyupload tagset downloaded usdownload data. , change file name default\nnlsy97unzip file. Find nlsy97.dat unzipped folderdrag file folder workIn R console, run line code belowAfter following steps, data working directory! \ncan load data quickly future typingWhy can’t just send data? Two reasons!NLSY97 created procedure register users encourage\nethical use data researchBy registering, help Bureau Labor Statistics know \nmany people using data, helpful demonstrating\nwide use data useful securing funding \nfuture surveys!","code":"\ninstall.packages(\"tidyverse\") # if you do not have it yet\ninstall.packages(\"Amelia\")    # if you do not have it yet\nsource(\"prepare_nlsy97.R\")\nlibrary(tidyverse)\nd <- readRDS(\"d.RDS\")"},{"path":"statistical-modeling.html","id":"worked-example-outcome-modeling","chapter":"5 Statistical modeling","heading":"5.8.2 Worked example: Outcome modeling","text":"Outcome modeling based following identification result, \ntranslates causal quantity statistical estimand \ninvolve counterfactual outcomes.\\[\\begin{aligned}\n&E(Y^) \\\\\n&\\text{law iterated expectation,}\\\\\n&= E(E(Y^\\mid \\vec{L})) \\\\\n&\\text{exchangeability,}\\\\\n&= E(E(Y^\\mid \\vec{L}, = )) \\\\\n&\\text{consistency,}\\\\\n&= E(E(Y\\mid \\vec{L}, = ))\n\\end{aligned}\\]use sample mean estimator outer expectation, \ndiscuss several estimators inner conditional\nexpectation. \\[\\begin{aligned}\n\\hat{E}(Y^) &= \\frac{1}{n}\\sum_{=1}^n \\hat{E}(Y\\mid \\vec{L} = \\vec\\ell_i, = )\n\\end{aligned}\\]Now intuition: estimator tells tofor unit \\(\\) sample, estimate expected outcome among\npeople look like unit (\\(\\vec{L} = \\vec\\ell_i\\)) got\ntreatment value interest \\(= \\).take average estimate unitsA nonparametric strategy step (1) literally estimate \nexpected outcome taking sample average among units \nidentical unit \\(\\) along confounders \\(\\vec{L}\\). \nmany confounding variables units, might zero\ncases! parametric strategy assume model outcome,\n\\[E(Y\\mid \\vec{L} = \\vec\\ell, = ) = \\alpha + \\beta + \\vec\\ell'\\vec\\gamma\\]\nparameters \\(\\{\\alpha,\\beta,\\vec\\gamma\\}\\) estimated \nOrdinary Least Squares regression.Note: model like! example, add\ninteractions use logistic regression instead.model, want predict expected outcome \ntreatment value \\(\\) every unit unit’s observed confounder\nvalues.\\[\\hat{E}(Y\\mid \\vec{L} = \\vec\\ell_i, = ) = \\hat\\alpha + \\hat\\beta + \\vec\\ell'_i\\hat{\\vec\\gamma}\\]\ncode, wouldmodify every unit’s treatment value \\(\\)\nintuition: actually intervened treatment \nworld, value treatment change values \n\\(\\vec{L}\\) remain unchanged\nintuition: actually intervened treatment \nworld, value treatment change values \n\\(\\vec{L}\\) remain unchangedpredict outcome every unitaverage sampleIn code , estimated three causal quantities\\(E(Y^1)\\), probability respondent \ncollege-educated spouse partner intervened assign \ncollege degree \\(E(Y^0)\\), probability respondent \ncollege-educated spouse partner intervened assign \ncollege degree \\(E(Y^1-Y^0)\\), average causal effect college degree \nspouse partner college degree","code":"\noutcome_model <- lm(y ~ a + sex + race + \n                      mom_educ + dad_educ + \n                      log_parent_income +\n                      log_parent_wealth +\n                      test_percentile,\n                    data = d)\n# Make data where all are treated\nd_if_treated <- d %>%\n  mutate(a = \"college\")\n# Make data where all are untreated\nd_if_untreated <- d %>%\n  mutate(a = \"no_college\")\npredicted_outcome <- d %>%\n  mutate(yhat1 = predict(outcome_model,\n                         newdata = d_if_treated),\n         yhat0 = predict(outcome_model,\n                         newdata = d_if_untreated))\npredicted_outcome %>%\n  summarize(average_yhat1 = mean(yhat1),\n            average_yhat0 = mean(yhat0),\n            average_effect = mean(yhat1 - yhat0))## # A tibble: 1 × 3\n##   average_yhat1 average_yhat0 average_effect\n##           <dbl>         <dbl>          <dbl>\n## 1         0.427         0.164          0.263"},{"path":"statistical-modeling.html","id":"worked-example-treatment-modeling","chapter":"5 Statistical modeling","heading":"5.8.3 Worked example: Treatment modeling","text":"Using different identification result, can also proceed \nparametric model treatment instead outcome. \nstrategy, population mean outcome \\(E(Y^)\\) treatment \\(\\)\nequals weighted average units observed treatment,\nweighted weight equalswhen \\(= \\), inverse probability treatmentwhen \\(\\neq \\), zeroBelow identification proof inverse probability treatment\nweighting.math complicated, intuition simpler: \nweighting, create pseudo-population treatment \\(\\) \nindependent confounders \\(\\vec{L}\\). , need know\npropensity score: probability observed treatment value\ngiven confounders.identification result points toward inverse probability \ntreatment weighting estimator known Horvitz-Thompson estimator,\n\\[\\hat{E}(Y^) = \\frac{1}{n}\\sum_{=1}^n \\frac{Y_i\\mathbb{}(A_i=)}{\\hat{P}(= \\mid\\vec{L} = \\vec\\ell_i)}\\]\nrelated estimator often used Hajek estimator, \nnormalizes weights sum 1.\n\\[\\hat{E}(Y^) = \\frac{1}{\\sum_{=1}^n\\frac{\\mathbb{}(A_i=)}{\\hat{P}(= \\mid \\vec{L} = \\vec\\ell_i)}}\\sum_{=1}^n \\frac{Y_i\\mathbb{}(A_i=)}{\\hat{P}(= \\mid\\vec{L} = \\vec\\ell_i)}\\]code, wouldestimate model probability treatment given confounders,\nexample logistic regressionfor every unit, predict probability \\(= \\text{College}\\)estimate probability treatment observedfor went college, equals p_collegefor , equals 1 - p_collegeThis quantity often called propensity score. encapsulates\ninformation contained confounders probability \ntreatment.estimate mean outcomes among treatment, weighted \ninverse propensity score. actually two ways \n.Horvitz-Thompson estimator relies fact true\npropensity scores sum number observationsthe Hajek estimator uses weighted mean, thus normalizing weights\nsum 1While asymptotically valid, finite-sample reasons \nprefer second estimator (Hajek).","code":"\ntreatment_model <- glm(I(a == \"college\") ~ \n                         sex + race + \n                         mom_educ + dad_educ + \n                         log_parent_income +\n                         log_parent_wealth +\n                         test_percentile,\n                       data = d,\n                       family = binomial)\npredicted_p_college <- d %>%\n  mutate(p_college = predict(treatment_model,\n                             # the line below tells R\n                             # to predict a probability\n                             # rather than log odds\n                             type = \"response\"))\npredicted_p_scores <- predicted_p_college %>%\n  mutate(propensity_score = case_when(\n    a == \"college\" ~ p_college,\n    a == \"no_college\" ~ 1 - p_college\n  ))\npredicted_p_scores %>%\n  summarize(y1 = mean(y * I(a == \"college\") / propensity_score),\n            y0 = mean(y * I(a == \"no_college\") / propensity_score))## # A tibble: 1 × 2\n##      y1    y0\n##   <dbl> <dbl>\n## 1 0.374 0.164\npredicted_p_scores %>%\n  group_by(a) %>%\n  summarize(estimate = weighted.mean(y, w = 1 / propensity_score))## # A tibble: 2 × 2\n##   a          estimate\n##   <chr>         <dbl>\n## 1 college       0.401\n## 2 no_college    0.163"},{"path":"statistical-modeling.html","id":"worked-example-matching","chapter":"5 Statistical modeling","heading":"5.8.4 Worked example: Matching","text":"also estimate matching. Matching can interpreted \noutcome modeling strategy conditional mean outcome\n\\(E(Y\\mid\\vec{} = , \\vec{L} = \\vec\\ell_i)\\) estimated mean\noutcome among set units whose confounder values similar \nunit \\(\\) received treatment value \\(\\) interest.One way defining ``similar’’ propensity score matching: find\nunits whose probability treatment given confounders close \nprobability unit \\(\\). example, code ,estimates probability college completion using logistic\nregressionfor person finished college, matches non-college\ngraduate whose probability completing college similarThe variable matched$weights one element person \ndataset. indicates many times person appears matched\nsample. are1,533 college graduates weight 11,533 matched non-graduates weight 14,705 non-matched non-graudates weight 0Within matched data, non-graduates graduates similar\nalong confounding variables. estimatethe probability college educated spouse among college\ngraduates mean among peoplethe probability persisted \nfinished college, mean among matched counterpartsAn even better estimator might use linear regression adjust \ndifferences within matched pairs exist matches \nidentical., predict potential outcoems matched fit report \nexpected outcome among college graduates factual treatment\nunderThese results suggest completing college increases probability\ncollege-educated spouse partner 27 percentage\npoints.","code":"\nlibrary(MatchIt)\nmatched <- matchit(a == \"college\" ~ sex + race + mom_educ + \n                     dad_educ + log_parent_income + \n                     log_parent_wealth + test_percentile,\n                   method = \"nearest\", \n                   distance = \"glm\",\n                   estimand = \"ATT\",\n                   data = d)\ntable(d$a,matched$weights)##             \n##                 0    1\n##   college       0 1533\n##   no_college 4705 1533\nd %>%\n  mutate(weight = matched$weights) %>%\n  group_by(a) %>%\n  summarize(p_spouse_college = weighted.mean(y, w = weight))## # A tibble: 2 × 2\n##   a          p_spouse_college\n##   <chr>                 <dbl>\n## 1 college               0.528\n## 2 no_college            0.232\nmatched_fit <- lm(y ~ a*(sex + race + mom_educ + \n                           dad_educ + log_parent_income + \n                           log_parent_wealth + test_percentile), \n                  data = d, \n                  weights = matched$weights)\n# Create data frames for prediction\ncollege_grads_factual <- d %>%\n  filter(a == \"college\")\ncollege_grads_counterfactual <- college_grads_factual %>%\n  mutate(a = \"no_college\")\n\n# Predict outcomes from the model\ncollege_grads_factual %>%\n  mutate(yhat_college = predict(matched_fit, \n                                newdata = college_grads_factual),\n         yhat_no_college = predict(matched_fit,\n                                   newdata = college_grads_counterfactual)) %>%\n  # Report estimated average outcomes\n  select(starts_with(\"yhat\")) %>%\n  summarize_all(.funs = mean) %>%\n  # Estimate the causal effect\n  mutate(effect = yhat_college - yhat_no_college)## # A tibble: 1 × 3\n##   yhat_college yhat_no_college effect\n##          <dbl>           <dbl>  <dbl>\n## 1        0.528           0.259  0.269"},{"path":"front-door.html","id":"front-door","chapter":"6 Front door","heading":"6 Front door","text":"Oct 12. Slides. class, read Hernán Robins 2020 Technical Point 7.4. Optionally, see Glynn Kashin 2018This lecture engage new methods causal identification beyond backdoor adjustment. learning goals generalengage new causal identification approachtranslate method codecritique identification assumptionsFront door methods causal identification one case use show building blocks already know prepared learn new approaches causal identification.","code":""},{"path":"front-door.html","id":"identification","chapter":"6 Front door","heading":"Identification","text":"focus simplest case front door identification, depicted DAG variables \\(\\), \\(M\\), \\(Y\\) binary.setting, slides show following identification result.\\[P(Y^)=\\sum_m P(M = m\\mid = ) \\sum_{'}P(= ')P(Y\\mid M = m, = ')\\]","code":""},{"path":"front-door.html","id":"code-example","chapter":"6 Front door","heading":"Code example","text":"lecture slides translate method code one simulated example. providing code make easy copy follow along.Examine descriptive relationship \\(\\) \\(Y\\).Estimate probability \\(M\\) given \\(\\). causal assumptions, corresponds expected value \\(M\\) assignment value \\(\\) since \\(M\\rightarrow \\) unconfounded.Within front-door identification formula, need marginal probability treatment value.also need outcome distribution given \\(M\\) \\(\\).Given , can use backdoor adjustment identify outcome intervention \\(M\\) backdoor adjustment \\(\\).Bringing together, front-door identification.","code":"\nlibrary(tidyverse)\nsim_data <- function(n = 100) {\n  data.frame(U = runif(n)) %>%\n    # Generate a binary treatment\n    mutate(A = rbinom(n(), \n                      prob = U, \n                      size = 1)) %>%\n    # Generate a binary mediator\n    mutate(M = rbinom(n(), \n                      prob = .1 + .8*A, \n                      size = 1)) %>%\n    # Generate a binary outcome\n    mutate(Y = rbinom(n(), \n                      prob = plogis(U + .5*M), \n                      size = 1))\n}\ndata <- sim_data(n = 10e3)\ndata %>%\n  group_by(A) %>%\n  summarize(Y = mean(Y))## # A tibble: 2 × 2\n##       A     Y\n##   <int> <dbl>\n## 1     0 0.577\n## 2     1 0.748\np_M_given_A <- data %>%\n  # Count size of each group\n  group_by(A, M) %>%\n  count() %>%\n  # Convert to probability within A\n  group_by(A) %>%\n  mutate(p_M_under_A = n / sum(n)) %>%\n  select(A,M,p_M_under_A) %>%\n  print()## # A tibble: 4 × 3\n## # Groups:   A [2]\n##       A     M p_M_under_A\n##   <int> <int>       <dbl>\n## 1     0     0      0.907 \n## 2     0     1      0.0934\n## 3     1     0      0.102 \n## 4     1     1      0.898\n# Probability of each A\np_A <- data %>%\n  # Count size of each group\n  group_by(A) %>%\n  count() %>%\n  # Convert to probability\n  ungroup() %>%\n  mutate(p_A = n / sum(n)) %>%\n  select(A,p_A) %>%\n  print()## # A tibble: 2 × 2\n##       A   p_A\n##   <int> <dbl>\n## 1     0 0.502\n## 2     1 0.498\n# Probability of Y = 1 given M and A\np_Y_given_M_A <- data %>%\n  group_by(A,M) %>%\n  summarize(P_Y_given_A_M = mean(Y),\n            .groups = \"drop\") %>%\n  print()## # A tibble: 4 × 3\n##       A     M P_Y_given_A_M\n##   <int> <int>         <dbl>\n## 1     0     0         0.571\n## 2     0     1         0.640\n## 3     1     0         0.603\n## 4     1     1         0.764\n# Probability of Y = 1 under intervention on M\np_Y_under_M <- p_Y_given_M_A %>%\n  left_join(p_A, by = \"A\") %>%\n  group_by(M) %>%\n  summarize(p_Y_under_M = sum(P_Y_given_A_M  * p_A)) %>%\n  print()## # A tibble: 2 × 2\n##       M p_Y_under_M\n##   <int>       <dbl>\n## 1     0       0.587\n## 2     1       0.702\n# Probability of Y = 1 under intervention on A\np_Y_under_A <- p_M_given_A %>%\n  left_join(p_Y_under_M,\n            by = \"M\") %>%\n  group_by(A) %>%\n  summarize(estimate = sum(p_M_under_A * p_Y_under_M)) %>%\n  print()## # A tibble: 2 × 2\n##       A estimate\n##   <int>    <dbl>\n## 1     0    0.598\n## 2     1    0.690"},{"path":"instrumental-variables.html","id":"instrumental-variables","chapter":"7 Instrumental variables","heading":"7 Instrumental variables","text":"","code":""},{"path":"instrumental-variables.html","id":"experimental-settings","chapter":"7 Instrumental variables","heading":"7.1 Experimental settings","text":"Oct 17. Slides.instrumental variable (IV) identification strategy applies treatment effect \\(\\) \\(Y\\) confounded unobserved variables (\\(U\\)), instrument \\(Z\\) creates random unconfounded variation \\(\\).clean setting IV randomized experiments non-compliance: experimenter randomizes assigned treatment (\\(Z\\)) actual treatment (\\(\\)) may unequal \\(Z\\) units follow assignment. first class discuss setting.","code":""},{"path":"instrumental-variables.html","id":"lab-instrumental-variable-analysis-in-code","chapter":"7 Instrumental variables","heading":"7.2 Lab: Instrumental Variable analysis in Code","text":"lab implement instrumental variables estimators R.October 18 Slides. Download \nR Markdown file . Update:\nSolutions coding exercise .","code":""},{"path":"instrumental-variables.html","id":"observational-settings","chapter":"7 Instrumental variables","heading":"7.3 Observational settings","text":"Oct 19 Slides. class, read Hernán Robins 2020 Chapter 16.Thursday, move IV analysis observational settings. focus casual assumptions required IV. assumptions often hold design experiments non-compliance. observational settings, can doubtful.","code":""},{"path":"regression-discontinuity.html","id":"regression-discontinuity","chapter":"8 Regression discontinuity","heading":"8 Regression discontinuity","text":"","code":""},{"path":"regression-discontinuity.html","id":"introduction","chapter":"8 Regression discontinuity","heading":"8.1 Introduction","text":"Oct 24. Slides. class, read Huntington Klein 2021 Chapter 20, sections 20.1 20.3.4.settings, treatment assigned based solely value continuous variable. situations, can identify local ATE without many additional assumptions. Today introduce works using regression discontinuity designs.","code":""},{"path":"regression-discontinuity.html","id":"lab-regression-discontinuity---bandwidth-and-examples","chapter":"8 Regression discontinuity","heading":"8.2 Lab: Regression Discontinuity - Bandwidth and Examples","text":"Oct 25 lab, read Huntington Klein 2021 Chapter 20, section 20.2.1.\nSlides Download today’s .Rmd document .’ll discuss bandwidth selection triangular weighting. ’ll also apply regression discontinuity concrete example give chance try .","code":""},{"path":"regression-discontinuity.html","id":"discussion","chapter":"8 Regression discontinuity","heading":"8.3 Discussion","text":"Oct 26. Slides. class, read Huntington Klein 2021 Chapter 20, sections 20.2.2. 20.3.1.’ll continue discussion regression discontinuity designs discussing fuzzy RDD validation checks RDD.","code":""},{"path":"difference-in-difference.html","id":"difference-in-difference","chapter":"9 Difference in difference","heading":"9 Difference in difference","text":"","code":""},{"path":"difference-in-difference.html","id":"introduction-1","chapter":"9 Difference in difference","heading":"9.1 Introduction","text":"Oct 31. Slides. reading required, reference see Card & Krueger 1994Today study effect policy change New Jersey, drawing evidence neighboring state Pennsylvania.Difference difference identification strategy used one units become treated time point others . believe assumption parallel trends, can use change time never-treated units estimate change time experienced units become treated, counterfactual world become treated.","code":""},{"path":"difference-in-difference.html","id":"lab","chapter":"9 Difference in difference","heading":"9.2 Lab","text":"Nov 1 Slides. Download \nR Markdown file .lab, implement difference difference estimator specific setting. example comes Malesky, Nguyen, & Tran 2014 closely follow re-analysis data Egami & Yamauchi 2023.","code":""},{"path":"difference-in-difference.html","id":"extensions-of-did","chapter":"9 Difference in difference","heading":"9.3 Extensions of DID","text":"Nov 2. Slides. reading required, reference see Egami & Yamauchi 2023How know parallel trends assumption holds? hold? class discusses recent extensions framework.","code":""},{"path":"synthetic-control.html","id":"synthetic-control","chapter":"10 Synthetic control","heading":"10 Synthetic control","text":"","code":""},{"path":"synthetic-control.html","id":"introduction-2","chapter":"10 Synthetic control","heading":"10.1 Introduction","text":"Nov 7 Slides.","code":""},{"path":"synthetic-control.html","id":"lab-1","chapter":"10 Synthetic control","heading":"10.2 Lab","text":"Nov 8 SlidesWe review main idea behind synthetic control well compare contrast synthetic control matching difference--differences. also dig deeper select weights synthetic control review worked example assess performance method.","code":""},{"path":"synthetic-control.html","id":"discussion-1","chapter":"10 Synthetic control","heading":"10.3 Discussion","text":"Nov 9 Slides. (Updated explanation interference).\nclass, read Chapter 10 Causal Inference Mixtape Cunningham 2021","code":""},{"path":"data-driven-methods.html","id":"data-driven-methods","chapter":"11 Data-driven methods","heading":"11 Data-driven methods","text":"","code":""},{"path":"data-driven-methods.html","id":"introduction-3","chapter":"11 Data-driven methods","heading":"11.1 Introduction","text":"Nov 14 Slides.given intervention, subgroups people respond others. Ideas machine learning can help us target human attention toward subgroups.Concrete example. responds nudget go walk? Imagine first conduct survey asks people much love fall, (\\(X = 1\\) least) (\\(X = 10\\) ). randomize control condition (\\(= \\texttt{untreated}\\)) treatment condition (\\(= \\texttt{treated}\\)) encourages go walk outside. outcome \\(Y\\) active minutes day, recorded activity tracker.Simulated data. real data, can difficult evaluate causal estimators truth unknown. Today use data simulated known process order study properties estimators. code prepare R environment function simulate_sample() generate data 50 observations.example code simulate data:Causal estimands. example, like estimate \\[\\tau_x = E(\\underbrace{Y^1 - Y^0}_{\\substack{\\text{effect }\\\\\\text{nudge walk}\\\\\\text{active}\\\\\\text{minutes}}}\\mid \\underbrace{X = x}_{\\substack{\\text{among }\\\\\\text{love }\\\\\\text{fall = }x}})\\]\nvalue \\(x = 1,\\dots,10\\). estimands average causal effect nudge walk (\\(\\)) active minutes (\\(Y\\)) within subgroups defined value scale love fall (\\(X\\)).Identification. simulate data, \\(\\) assigned random. backdoor paths \\(\\) \\(Y\\).Estimator. estimator function takes dataset returns estimates. nonparametric estimator setting.can apply estimator follows.Task. Using sample simulated computer, estimate average causal effect \\(\\) \\(Y\\) within subgroups defined \\(X\\). Report two numbers us.value \\(X\\) estimated effect \\(\\) positive?effect estimate?discuss distribution estimates get class.ready early, think might evaluate performance approach many repeated simulations.","code":"\nlibrary(tidyverse)\nsource(\"https://raw.githubusercontent.com/causal3900/causal3900.github.io/main/assets/data/simulate_sample.R\")\nsimulated <- simulate_sample()##   X         A        Y\n## 1 1 untreated 76.07505\n## 2 1   treated 14.08178\n## 3 1 untreated 68.41982\n## 4 1   treated 18.42751\n## 5 1 untreated 48.99367\n## 6 2   treated 16.97469\nestimator <- function(data) {\n  data %>%\n    # Group by treatment A and confounder X\n    group_by(A, X) %>%\n    # Summarize by the average outcome within groups\n    summarize(Y = mean(Y),\n              .groups = \"drop\") %>%\n    # Reshape the data\n    pivot_wider(names_from = \"A\",\n                values_from = \"Y\",\n                names_prefix = \"y_\") %>%\n    # Estimate the effect within groups\n    mutate(effect = y_treated - y_untreated)\n}\nestimate <- estimator(simulated)"},{"path":"data-driven-methods.html","id":"machine-learning-approaches","chapter":"11 Data-driven methods","heading":"11.2 Machine learning approaches","text":"Nov 16 Slides.Today generalize ideas Tuesday. discuss sample splitting makes easier tochoose among many estimandschoose among many estimatorsdevelop new data science approaches","code":""},{"path":"current-research.html","id":"current-research","chapter":"12 Current research","heading":"12 Current research","text":"","code":""},{"path":"current-research.html","id":"research-discussion-sam","chapter":"12 Current research","heading":"12.1 Research discussion: Sam","text":"Nov 21 SlidesToday discussing causal discovery: might learn DAGs data","code":""},{"path":"current-research.html","id":"research-discussion-ian","chapter":"12 Current research","heading":"12.2 Research discussion: Ian","text":"Nov 28 Slides can optionally read project page: ilundberg.github.io/pstratreg.Sometimes treatment causes outcome undefined. problem well-studied randomized controlled trials biostatistics, people die end trial. talk applications idea study inequality require adjustment measured confounding. joint work Soonhong Cho (PhD Candidate, UCLA Political Science).","code":""},{"path":"course-recap.html","id":"course-recap","chapter":"13 Course recap","heading":"13 Course recap","text":"Nov 30 SlidesWe review learned semester!","code":""},{"path":"discussion-2.-stats-review.html","id":"discussion-2.-stats-review","chapter":"Discussion 2. Stats review","heading":"Discussion 2. Stats review","text":"SlidesTo execute simulations locally, download .Rmd ","code":"\nlibrary(ggplot2)\nlibrary(ggmosaic)\nlibrary(tibble)"},{"path":"discussion-2.-stats-review.html","id":"sample-expectations-converge-to-population","chapter":"Discussion 2. Stats review","heading":"13.1 Sample expectations converge to population","text":"can generate simulations show sample mean variance converge \npopulation values.","code":"\ntrue_mean <- 2\ntrue_var <- 5\n\nsample_mean_seq <- 1:3000\nsample_means <- vapply(\n  sample_mean_seq,\n  \\(x) mean(rnorm(n = x, mean = true_mean, sd = sqrt(true_var))),\n  numeric(1)\n)\nsample_variances <- vapply(\n  sample_mean_seq,\n  \\(x) {\n    data <- rnorm(n = x, mean = true_mean, sd = sqrt(true_var))\n    sample_mean <- mean(data)\n    sum((data - sample_mean)^2)/length(data)\n  },\n  numeric(1)\n)\n\nmeans <- tibble(\"N\" = sample_mean_seq, \"Sample Mean\" = sample_means)\nvars <- tibble(\"N\" = sample_mean_seq, \"Sample Variance\" = sample_variances)\n\ncolors <- c(\"Sample Mean\" = \"lightblue\", \"Population Mean\" = \"red\")\n\nggplot(means, aes(y = `Sample Mean`, x = N)) +\n  geom_line(color = \"lightblue\") +\n  geom_abline(slope = 0, intercept = true_mean, color = \"red\") +\n  theme_bw()\nggplot(vars, aes(y = `Sample Variance`, x = N)) +\n  geom_line(color = \"lightblue\") +\n  geom_abline(slope = 0, intercept = true_var, color = \"red\") +\n  theme_bw()"},{"path":"discussion-2.-stats-review.html","id":"simulate-conditional-expectations","chapter":"Discussion 2. Stats review","heading":"13.2 Simulate conditional expectations","text":"Simulate conditional expectations within groups differ sample\nmean.","code":"\ngroup1_means <- rnorm(100, mean = 20, sd = 5)\ngroup2_means <- rnorm(100, mean = 30, sd = 5)\ngroup_means <- data.frame(\n  \"Group\" = c(rep(\"Group 1\", 100), rep(\"Group 2\", 100)),\n  \"Values\" = c(group1_means, group2_means),\n  \"x\" = rnorm(200, 5, sd = 3)\n)\nggplot(group_means, aes(x = x, y = Values, color = Group)) +\n  geom_point() +\n  geom_abline(\n    slope = 0,\n    intercept = mean(group_means$Values),\n    show.legend = TRUE,\n    color = \"gray30\"\n  ) +\n  geom_abline(\n    slope = 0,\n    intercept = mean(group_means[group_means$Group == \"Group 1\", ]$Values),\n    show.legend = TRUE,\n    color = \"#F8766D\"\n  ) +\n  geom_abline(\n    slope = 0,\n    intercept = mean(group_means[group_means$Group == \"Group 2\", ]$Values),\n    show.legend = TRUE,\n    color = \"#00BFC4\"\n  ) +\n  theme_bw()"},{"path":"discussion-2.-stats-review.html","id":"show-independence-of-variables---example-of-two-dice-rolling","chapter":"Discussion 2. Stats review","heading":"13.3 Show independence of variables - example of two dice rolling","text":"","code":"\ndice_1 <- sample(1:6, 100000, replace = TRUE)\ndice_2 <- sample(1:6, 100000, replace = TRUE)\ndice <- tibble(\n  \"dice\" = c(rep(\"Die 1\", 100000), rep(\"Die 2\", 100000)),\n  \"value\" = c(dice_1, dice_2)\n)\n\nggplot(data = dice) +\n  geom_mosaic(aes(x = product(dice, value), fill = dice)) +   \n  labs(y=\"\", x=\"Value Rolled\", title = \"Independence of dice roll\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"discussion-3.-analyzing-an-experiment-in-r","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"Discussion 3. Analyzing an Experiment in R","text":"Slides","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"download-.rmd-document","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.4 Download .Rmd Document","text":"Download today’s .Rmd document .","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"get-out-and-vote-experiment","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.5 Get out and Vote Experiment","text":"lab, explore experiment digs mechanisms\nunderlying people vote. exercise based :Gerber, Alan S., Donald P. Green, Christopher W. Larimer. “Social Pressure Voter Turnout: Evidence Large-scale Field Experiment.” American Political Science Review 102.1 (2008): 33-48.long-standing theory many people\nvote driven social norms (e.g. understanding voting\ncivic duty). theory, dominant theoretical\nexplanation, little empirical backing long time. experiment\nexamines theory asking question:\nextent social norms cause voter turnout?","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"experimental-design","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.5.1 Experimental Design","text":"order answer question, approximately 80,000 Michigan households\nrandomly assigned treatment control groups, treatment\ngroup randomly assigned one four possible treatment arms. \ntreatment arms varied intensity social pressure conveyed,\ndefined follows:first treatment arm mailed letter simply reminded \nvoting civic duty.second treatment arm mailed letter telling researchers\nstudying voting turnout based public records.third treatment arm mailed letter stating voting turnout\nrevealed members household.fourth treatment arm mailed letter stating voting turnout\nrevealed household neighbors.","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"analyze-experiment","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6 Analyze Experiment","text":"","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"necessary-packages","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.1 Necessary packages","text":"Note: errors probably either don’t dplyr haven\ninstalled.","code":"\nlibrary(dplyr)\nlibrary(haven)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"import-data","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.2 Import data","text":"Alternatively (really want), download data load directly computer. Make sure save data directory RMarkdown file .\ncan can import data :gotv <- read_dta(\"social_pressure.dta\")Run following code get quick peek dataset using function glimpse. returns info number rows/columns, column names, type data column. Notice information year birth yob explicitly age. Also notice treatments labeled numbers 0 4.","code":"\ngotv <- read_dta(\"https://causal3900.github.io/assets/data/social_pressure.dta\")\nglimpse(gotv)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"clean-data","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.3 Clean data","text":"First, let’s construct age variable describing old (number years)\nperson year 2006. yob variable says year person\nborn . , use mutate function, can read .Given person’s year birth, calculate age year 2006? Note can arithmetic operations information dataset. example, two columns col_1 col_2 wanted create third column called col_3 sum two columns, write:mutate(col_3 = col_1 + col_2)code started . Fill appropriate expression age = add column gotv labeled age contains old person 2006.Now, convert treatment variable ’s numeric representation \ncorresponding labels are0: “Control”1: “Hawthorne” (‘researchers viewing records via public data’ treatment arm)2: “Civic Duty” (‘voting civic duty’ treatment arm)3: “Neighbors” (‘voting turnout revealed neighbors’ treatment arm)4: “Self” (‘voting turnout revealed household’ treatment arm), want use function case_when described .\ngeneral syntax case_when(condition ~ output-value)example, condition treatement == 0 output value \"Control\". search every value treatment column equals 0 replace string \"Control\".started code . Decide argument(s) pass inside parantheses case_when().Now, use glimpse see added age variable treatments word instead number labels.","code":"\ngotv <- gotv |>\n  mutate(age = )\ngotv <- gotv |>\n  mutate(treatment = case_when()) \nglimpse(gotv)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"balance-table","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.4 Balance table","text":"Next, ’re going confirm control treatment groups look pretty\nmuch across set covariates, .e. two groups balanced covariates. Specifically means ’re going calculate mean value set covariates across treatment/control\narms, expect pretty much equal randomization worked. related idea exchangeability.exercise, going reproduce table similar Table 1 paper. want table shows mean value following covariates five treatment arms: Household size, Nov 2002, Nov 2000, Aug 2004, Aug 2002, Aug 2000, Female, Age (years). create table 5 rows, one treatment arm, 8 columns, one covariate interest.started code . need :Pass argument group_by() calculate seperate means treatment arm.\nLook documentation group_by function.\nLook documentation group_by function.Pass argument summarise() computes mean covariate covariates seperate treatment arm.\nLook documentation summarise function.\nmay find function across useful well. can use function inside summarise()!\nLook documentation summarise function.may find function across useful well. can use function inside summarise()!Note numbers match exactly Table 1. want notice values column similar across rows.","code":"\ncovariates <- c(\"sex\", \"age\", \"g2000\", \"g2002\", \"p2000\", \"p2002\", \"p2004\", \"hh_size\")\n\ngotv_balance <- gotv |>\n  group_by(...) |>\n  summarise(...)\n\nprint(gotv_balance)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"results","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.5 Results","text":"Finally, let’s replicate final results (Table 2). treatment group, calculate percentage individuals got voted, well total number individuals group! started code . need toPass argument group_by() working treatment arm seperately (!)Pass two arguments summarise() following:\nCreate column titled Percentage_Voting contains percent group voted\nCreate column titled num_of_individuals contains total number people group\nCreate column titled Percentage_Voting contains percent group votedCreate column titled num_of_individuals contains total number people group","code":"\ngotv_results <- gotv |>\n  group_by(...) |>\n  summarise(...)\n\nprint(gotv_results)"},{"path":"due-dates.html","id":"due-dates","chapter":"Due dates","heading":"Due dates","text":"’ll post due dates throughout semester.","code":""},{"path":"due-dates.html","id":"upcoming","chapter":"Due dates","heading":"Upcoming","text":"Pset 2: Due Tuesday, September 24th 11:59pm via CanvasPset 2: Due Tuesday, September 24th 11:59pm via CanvasPset 2 Peer Reviews: Due Tuesday, October 1st 11:59pm via CanvasPset 2 Peer Reviews: Due Tuesday, October 1st 11:59pm via CanvasProject Task 1: Due Thursday, October 3rd 11:59pm via CanvasProject Task 1: Due Thursday, October 3rd 11:59pm via Canvas","code":""},{"path":"due-dates.html","id":"past","chapter":"Due dates","heading":"Past","text":"Pset 1: Due Tuesday, September 10th 5pm via CanvasPset 1: Due Tuesday, September 10th 5pm via CanvasPset 1 Peer Reviews: Due Tuesday, September 17th 5pm via CanvasPset 1 Peer Reviews: Due Tuesday, September 17th 5pm via Canvas","code":""},{"path":"course-project.html","id":"course-project","chapter":"Course Project","heading":"Course Project","text":"course project opportunity engage course content via real-world example. course semester, walk entire causal analysis: starting defining causal question way communicating results analysis. Parts project done individuals parts completed group. assign parts project throughout semester give detailed instructions time. also plenty check-ins along way make sure ’re right track.Project Overview expectationsTask 1 Details .Rmd file fill outTask 2 DetailsTask 3 DetailsTask 4 DetailsTask 5 Details","code":""},{"path":"problem-set-1.-definitions.html","id":"problem-set-1.-definitions","chapter":"Problem Set 1. Definitions","heading":"Problem Set 1. Definitions","text":"Relevant material covered Aug 29. Problem set due Sept 10 5pm.Welcome problem set! homework practice conceptual notation ideas descriptive causal inference.complete problem set, Download .Rmd complete homework. Omit name can anonymous peer feedback. Compile PDF submit PDF Canvas.","code":""},{"path":"problem-set-1.-definitions.html","id":"practice-with-potential-outcomes","chapter":"Problem Set 1. Definitions","heading":"1. Practice with potential outcomes","text":"Jose says coming Cornell caused discover statistics, became major! says gone NYU, stuck biology.","code":""},{"path":"problem-set-1.-definitions.html","id":"points","chapter":"Problem Set 1. Definitions","heading":"1.1 (7 points)","text":"Jose’s claim, treatment?Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-1","chapter":"Problem Set 1. Definitions","heading":"1.2 (7 points)","text":"Using mathematical notation discussed class, define two potential outcomes Jose referringAnswer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-2","chapter":"Problem Set 1. Definitions","heading":"1.3 (7 points)","text":"sentence two, say Fundamental Problem Causal Inference applies Jose’s claim.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-3","chapter":"Problem Set 1. Definitions","heading":"1.4 (7 points)","text":"Using conditional expectations probabilities, write following math: probability majoring statistics higher among students attend Cornell among students attend NYU.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-4","chapter":"Problem Set 1. Definitions","heading":"1.5 (7 points)","text":"Give one reason average causal effect attending Cornell versus NYU (quantity 1.2, averaged students) might different average descriptive difference (1.4) rates majoring statistics.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"a-sailing-class","chapter":"Problem Set 1. Definitions","heading":"2. A sailing class","text":"looking sailing class Cornell Wellness! claim , tell us whether claim causal descriptive.","code":""},{"path":"problem-set-1.-definitions.html","id":"points-5","chapter":"Problem Set 1. Definitions","heading":"2.1 (5 points)","text":"Last year, survey students take class. proportion reporting felt prepared sail Cayuga Lake higher among took class.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-6","chapter":"Problem Set 1. Definitions","heading":"2.2 (5 points)","text":"Last year, survey students class. proportion reporting felt prepared sail Cayuga Lake higher survey taken class.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-7","chapter":"Problem Set 1. Definitions","heading":"2.3 (5 points)","text":"average, students class emerged prepared sail without class.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"session-info","chapter":"Problem Set 1. Definitions","heading":"Session info","text":"chunk record information R session, useful debugging issues homework assignments contain code.","code":"\nsessionInfo()## R version 4.3.1 (2023-06-16)\n## Platform: aarch64-apple-darwin20 (64-bit)\n## Running under: macOS Sonoma 14.5\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \n## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## time zone: America/New_York\n## tzcode source: internal\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets \n## [6] methods   base     \n## \n## loaded via a namespace (and not attached):\n##  [1] digest_0.6.33     R6_2.5.1          bookdown_0.35    \n##  [4] fastmap_1.2.0     xfun_0.47         cachem_1.1.0     \n##  [7] knitr_1.43        memoise_2.0.1     htmltools_0.5.8.1\n## [10] rmarkdown_2.22    lifecycle_1.0.3   xml2_1.3.4       \n## [13] cli_3.6.1         downlit_0.4.4     sass_0.4.9       \n## [16] withr_2.5.0       jquerylib_0.1.4   compiler_4.3.1   \n## [19] rstudioapi_0.14   tools_4.3.1       evaluate_0.21    \n## [22] bslib_0.8.0       yaml_2.3.7        fs_1.6.2         \n## [25] jsonlite_1.8.7    rlang_1.1.1"},{"path":"problem-set-2.-experiments.html","id":"problem-set-2.-experiments","chapter":"Problem Set 2. Experiments","heading":"Problem Set 2. Experiments","text":"Relevant material covered Sep 11. Problem set due Sep 24.complete problem set, Download .Rmd complete homework. Omit name can anonymous peer feedback. Compile PDF submit PDF Canvas.problem set based :Bertrand, M & Mullainathan, S. 2004. “Emily Greg Employable Lakisha Jamal? Field Experiment Labor Market Discrimination.” American Economic Review 94(4):991–1013.’s heads-hard problem setfor , reading social science paper hardfor , mathematical statistics hardfor , R coding hardFor almost one three easy.want support succeed! Text format help .","code":""},{"path":"problem-set-2.-experiments.html","id":"conceptual-questions-about-the-study-design","chapter":"Problem Set 2. Experiments","heading":"1. Conceptual questions about the study design","text":"Read first 10 pages paper (end section 2).","code":""},{"path":"problem-set-2.-experiments.html","id":"points-fundamental-problem","chapter":"Problem Set 2. Experiments","heading":"1.1. (5 points) Fundamental Problem","text":"One submitted resume name “Emily Baker.” yielded callback. resume name “Lakisha Washington.” Explain Fundamental Problem Causal Inference applies case (1–2 sentences).","code":""},{"path":"problem-set-2.-experiments.html","id":"points-exchangeability","chapter":"Problem Set 2. Experiments","heading":"1.2. (5 points) Exchangeability","text":"sentence, state exchangeability means study. concreteness, question may suppose names study “Emily Baker” “Lakisha Washington.”","code":""},{"path":"problem-set-2.-experiments.html","id":"points-something-you-liked","chapter":"Problem Set 2. Experiments","heading":"1.3. (10 points) Something you liked","text":"State something concrete appreciate study design, randomization.","code":""},{"path":"problem-set-2.-experiments.html","id":"analyzing-the-experimental-data","chapter":"Problem Set 2. Experiments","heading":"2. Analyzing the experimental data","text":"Load packages code use.complete rest assignment, need download study’s data OpenICPSR: https://www.openicpsr.org/openicpsr/project/116023/version/V1/view. require creating account agreeing terms using data ethically. Put data folder computer .Rmd located. Read data R using read_dta.error, might need set working directory first. tells R look data files. words, data file needs folder homework file, RStudio needs told folder look . top RStudio, click Session -> Set Working Directory -> Source File Location.now see d Global Environment top right RStudio.use four variables:2.1–2.4, think race treatment. 2.5–2.6, think firstname treatment.Restrict variables using select().new R, just happened:created new object d_selectedused assignment operator <- put something objectwe started data object dwe used pipe operator %>% hand d new actionthe action select() selected variables interestWe often analyze data starting data object handing series actions connected pipe %>%","code":"\nlibrary(tidyverse)\nlibrary(haven)\nd <- read_dta(\"assets/data/lakisha_aer.dta\")\nd <- read_dta(\"assets/data/lakisha_aer_aggregated.dta\")\nd_selected <- d %>%\n  select(call, firstname, race, sex)"},{"path":"problem-set-2.-experiments.html","id":"points-point-estimates-of-expected-potential-outcomes","chapter":"Problem Set 2. Experiments","heading":"2.1. (5 points) Point estimates of expected potential outcomes","text":"top Table 1 reports callback rates: 9.65% white names 6.45% Black names. Reproduce numbers. , take code add group_by() action d_selected summarize.’s reference introduces group_by summarize.","code":"\nd_summarized <- d_selected %>%\n  summarize(callback_rate = mean(call),\n            number_cases = n()) %>%\n  print()## # A tibble: 1 × 2\n##   callback_rate number_cases\n##           <dbl>        <int>\n## 1        0.0805         4870"},{"path":"problem-set-2.-experiments.html","id":"points-inference-for-expected-potential-outcomes","chapter":"Problem Set 2. Experiments","heading":"2.2. (5 points) Inference for expected potential outcomes","text":"Use mutate() (see reference page) create new columns containing standard error estimate well lower upper limits 95% confidence intervals.Suppose \\(\\pi^\\) probability callback treatment condition \\(\\). Let \\(\\hat\\pi^\\) estimate unknown probability, meaning \\(\\hat\\pi^\\) proportion people treatment condition receive callback experiment (computed 2.1). making confidence interval \\(\\hat\\pi^\\), estimate \\(\\hat\\pi^\\) standard error standard error \\(\\hat\\pi^\\)make easier, quick math review R functions can use.Standard error math. Let \\(Y^\\) Bernoulli random variable, taking value 1 random resume name \\(\\) yields callback 0 otherwise. Let \\(\\pi^= P(Y^=1)\\) probability callback. statistics, know variance \\(V(Y^) = \\pi^(1-\\pi^)\\). estimated average: \\(\\hat\\pi^= \\frac{1}{n_a}\\sum_{:A_i=} Y_i^\\). many times many hypothetical samples, always get estimate. fact, estimate sampling variance \\(V(\\hat\\pi^) = \\frac{\\pi^(1-\\pi^)}{n_a}\\). know \\(\\hat\\pi^\\) mean \\(n_a\\) independent identically distributed random variables \\(Y^\\). standard error square root sampling variance: \\(SE(\\hat\\pi^) = \\sqrt\\frac{\\pi^(1-\\pi^)}{n_a}\\). can estimate standard error plugging estimate \\(\\hat\\pi^\\) true unknown \\(\\pi^\\) wherever appears.Standard error code. translated standard error formula code . function accepts estimated probability p sample size n returns estimated standard error. can use se_binary() function code within mutate() just like mean() used within summarize() start problem set.Sampling distribution math. \\(\\hat\\pi^\\) sample mean, know something sampling distribution: limit sample size grows infinity, across hypothetical repeated samples distribution \\(\\hat\\pi^\\) estimates becomes Normal. Central Limit Theorem! Across repeated samples, middle 95% estimates fall within known range: \\(\\pi^\\pm \\Phi^{-1}(.975) \\times SE(\\hat\\pi^)\\), \\(\\Phi^{-1}()\\) inverse cumulative distribution function standard Normal distribution. might previously learned \\(\\Phi^{-1}(.975) \\approx 1.96\\), might familiar number 1.96.Sampling distribution graph.Confidence interval math. get 95% confidence interval plugging estimates \\(\\hat\\pi^\\) \\(\\widehat{SE}(\\hat\\pi^)\\) limits . interval centered estimate \\(\\hat\\pi^\\) nice property: repeatedly made confidence interval procedure using hypothetical samples population, interval contain unknown true parameter \\(\\pi^\\) 95% time.Confidence interval code. translated confidence interval formula code . functions accept estimate standard error return lower upper bounds (respectively) 95% confidence interval assumes Normal sampling distribution. can use functions code within mutate() just like mean() used within summarize() start problem set.","code":"\nse_binary <- function(p, n) {\n  se <- sqrt( p * (1 - p) / n )\n  return(se)\n}\nci_lower <- function(estimate, standard_error) {\n  estimate - qnorm(.975) * standard_error\n}\nci_upper <- function(estimate, standard_error) {\n  estimate + qnorm(.975) * standard_error\n}"},{"path":"problem-set-2.-experiments.html","id":"points-interpret-your-confidence-interval","chapter":"Problem Set 2. Experiments","heading":"2.3. (5 points) Interpret your confidence interval","text":"words, interpret confidence intervals. sure discuss property hypothetical repeated samples, sure frame answer using numbers variables actual experiment analyzing.","code":""},{"path":"problem-set-2.-experiments.html","id":"points-visualize-expected-potential-outcomes","chapter":"Problem Set 2. Experiments","heading":"2.4. (5 points) Visualize expected potential outcomes","text":"Using ggplot(), visualize estimated callback rate race. Use geom_point() point estimates geom_errorbar() confidence intervals, race x axis estimates y axis. Label axes using full words.never used ggplot, see Ch 3 R Data Science Hadley Wickham.","code":""},{"path":"problem-set-2.-experiments.html","id":"points-estimate-and-visualize-by-firstname","chapter":"Problem Set 2. Experiments","heading":"2.5. (5 points) Estimate and visualize by firstname","text":"distinct first names yield distinct effects? Repeat coding steps 2.2–2.4, now create estimates grouped race, sex, firstname. Visualize point estimates confidence intervals.One way visualize placing first names \\(x\\)-axis using facet_wrap() layer facet race sex.strategy visualize fine, long shows estimates firstname indicates race sex signaled firstname\n2.4, making two estimates: one white one Black. 2.5, aggregating within fine-grained set groups defined race, sex, firstname. need start fresh raw person-level data order answer 2.5","code":"\nyour_ggplot +\n  facet_wrap(~ race + sex,\n             scales = \"free_x\", \n             nrow = 1)"},{"path":"problem-set-2.-experiments.html","id":"points-interpret","chapter":"Problem Set 2. Experiments","heading":"2.6. (5 points) Interpret","text":"Within race sex, first names effect. Suppose true differences (due sampling variability). tell importance researcher decisions names use treatments? many possible right answers, asking think might mean research design names different effects.","code":""},{"path":"problem-set-3.-dags..html","id":"problem-set-3.-dags.","chapter":"Problem Set 3. DAGs.","heading":"Problem Set 3. DAGs.","text":"posted assignment yet.meantime, may reference Problem Set 3 Fall 2023, please note may significant changes.","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"problem-set-4.-statistical-modeling","chapter":"Problem Set 4. Statistical modeling","heading":"Problem Set 4. Statistical modeling","text":"posted assignment yet.meantime, may reference Problem Set 4 Fall 2023, please note may significant changes.","code":""},{"path":"problem-set-5.-iv-rd.html","id":"problem-set-5.-iv-rd","chapter":"Problem Set 5. IV + RD","heading":"Problem Set 5. IV + RD","text":"posted assignment yet.meantime, may reference Problem Set 5 Fall 2023, please note may significant changes.","code":""},{"path":"problem-set-6.-difference-in-difference-synthetic-control.html","id":"problem-set-6.-difference-in-difference-synthetic-control","chapter":"Problem Set 6. Difference in Difference + Synthetic Control","heading":"Problem Set 6. Difference in Difference + Synthetic Control","text":"posted assignment yet.meantime, may reference Problem Set 6 Fall 2023, please note may significant changes.","code":""},{"path":"who-we-are.html","id":"who-we-are","chapter":"Who we are","heading":"Who we are","text":"","code":""},{"path":"who-we-are.html","id":"faculty","chapter":"Who we are","heading":"Faculty","text":"enjoy thinking problems goal discover interpretable structure underlies data generating process. includes problems areas causal discovery, graphical models, mixed membership models. many cases, methods tailored high-dimensional setting number variables considered may large compared number observed samples. applied interests vary generally social science related.’m currently working problems causal inference network interference. think causal inference really cool applications across many different fields. ’m generally interested applications public health, social welfare, social good. free time, enjoy singing, dancing, cooking, watching movies, traveling various theme parks.","code":""},{"path":"who-we-are.html","id":"teaching-assistants","chapter":"Who we are","heading":"Teaching assistants","text":"currently working problem related Causality, particularly Causal Graph discovery Functional data. interested learn interpretable structures data hidden confounders. free time enjoy playing basketball, running hanging friends.currently working graphical models noisy measurements. interested causal discovery applications social science biology. free time like puzzles, playing pool, baking.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
