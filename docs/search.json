[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Cornell STSCI / INFO / ILRST 3900. Causal Inference. Fall 2023.Welcome! Together, learn make causal claims combining data arguments.Taught Ian Lundberg, Y. Samuel Wang, Mayleen Cortez-Rodriguez, Daniel Molitor. Read us !","code":""},{"path":"index.html","id":"learning-objectives","chapter":"Welcome","heading":"Learning objectives","text":"result participating course, students able todefine counterfactuals outcomes hypothetical interventionsidentify counterfactuals causal assumptions presented graphsestimate counterfactual outcomes pairing assumptions statistical evidence","code":""},{"path":"index.html","id":"is-this-course-for-me","chapter":"Welcome","heading":"Is this course for me?","text":"course designed upper-division undergraduate students. assume familiarity introductory statistics course level STSCI 2110, PAM 2100, PSYCH 2500, SOC 3010, ECON 3110, similar courses.Cornell student? welcome follow along site.","code":""},{"path":"index.html","id":"readings","chapter":"Welcome","heading":"Readings","text":"Especially beginning, course draws heavily onHernán, M.., J.M. Robins. 2020. Causal Inference: ? Boca Raton: Chapman & Hall / CRC.grateful authors excellent text.","code":""},{"path":"index.html","id":"organization-of-the-site","chapter":"Welcome","heading":"Organization of the site","text":"course module left panel span several lectures. Within module, right panel help navigate. build site course semester, uploading lecture slides go. tells bit teaching team.","code":""},{"path":"index.html","id":"land-acknowledgment","chapter":"Welcome","heading":"Land acknowledgment","text":"recognize university land acknowledgment, well additional emphasis Cornell American Indian Indigenous Studies Program.Cornell University located traditional homelands Gayogo̱hó:nǫɁ (Cayuga Nation). Gayogo̱hó:nǫɁ members Haudenosaunee Confederacy, alliance six sovereign Nations historic contemporary presence land. Confederacy precedes establishment Cornell University, New York state, United States America. acknowledge painful history Gayogo̱hó:nǫɁ dispossession, honor ongoing connection Gayogo̱hó:nǫɁ people, past present, lands waters.land acknowledgment reviewed approved traditional Gayogo̱hó:nǫɁ leadership.addition Gayogo̱hó:nǫɁ land acknowledgment separate , AIISP faculty like emphasize: Cornell’s founding enabled course national genocide sale almost one million acres stolen Indian land Morrill Act 1862. date university neither officially acknowledged complicity theft offered form restitution hundreds Native communities impacted. additional information, see Cornell University Indigenous Dispossession website.","code":""},{"path":"defining-counterfactuals.html","id":"defining-counterfactuals","chapter":"1 Defining counterfactuals","heading":"1 Defining counterfactuals","text":"","code":""},{"path":"defining-counterfactuals.html","id":"observing-versus-intervening","chapter":"1 Defining counterfactuals","heading":"1.1 Observing versus intervening","text":"Aug 22. SlidesStatistical inference observing: observe sample population, can infer population? Causal inference intervening: take sample population intervene change exposure, average outcome result?Today discuss observing, intervening, difference important.","code":""},{"path":"defining-counterfactuals.html","id":"lab-designing-a-study","chapter":"1 Defining counterfactuals","heading":"1.2 Lab: Designing a study","text":"Aug 23In lab, start getting know one another. , discuss hypothetical scenario.researcher (may disagree) says :\n> Coming office hours frequently causes student success classroom.groups 3 students, discuss following.Imagine start semester. design randomized experiment assess claim?\nImagine can assign students treatment condition comply\nConsider details: enroll, define frequently, assess success, etc.\nImagine can assign students treatment condition complyConsider details: enroll, define frequently, assess success, etc.Imagine end semester. randomized study run. want conduct observational study using administrative records (get IRB approval ). design observational study assess claim?expectation clear answers now. course semester learn formalize types questions solutions.","code":""},{"path":"defining-counterfactuals.html","id":"defining-causal-effects","chapter":"1 Defining counterfactuals","heading":"1.3 Defining causal effects","text":"Aug 24. Slides. class, read Chapter 1 Hernán Robins 2020 begin Homework 1.Today define average causal effects potential outcomes framework.end class, able todefine potential outcomesexplain Fundamental Problem Causal Inference1recall statistical concepts: random variables, expectation, conditional expectation","code":""},{"path":"exchangeability-and-experiments.html","id":"exchangeability-and-experiments","chapter":"2 Exchangeability and experiments","heading":"2 Exchangeability and experiments","text":"","code":""},{"path":"exchangeability-and-experiments.html","id":"randomized-experiments","chapter":"2 Exchangeability and experiments","heading":"2.1 Randomized experiments","text":"Aug 29. Slides. class, read Hernán Robins 2020 Chapter 2 end 2.1.Much course address observational studies non-randomized treatments. set stage, today first discuss randomized experiments powerful possible.","code":""},{"path":"exchangeability-and-experiments.html","id":"lab-statistics-review-with-math-and-simulations","chapter":"2 Exchangeability and experiments","heading":"2.2 Lab: Statistics review with math and simulations","text":"Aug 30. Slides.course use several ideas previous coursework statistics, including random variables, expected values, independence. lab review concepts math using simulations R.","code":""},{"path":"exchangeability-and-experiments.html","id":"exchangeability-and-conditional-randomization","chapter":"2 Exchangeability and experiments","heading":"2.3 Exchangeability and conditional randomization","text":"Aug 31. Slides. class, read Hernán Robins 2020 Chapter 2.2.talk experiments good: help us ask precise causal questions, setting key assumption (exchangeability) holds design. discuss exchangeability simple randomized experiments experiments conditionally randomized treatment assignment probabilities functions pre-existing characteristics.","code":""},{"path":"exchangeability-and-experiments.html","id":"standardization-and-effect-measures","chapter":"2 Exchangeability and experiments","heading":"2.4 Standardization and effect measures","text":"Sep 5. Slides. class, read Hernán Robins 2020 Chapter 1.3 2.3.Standardization important statistical procedure two steps:estimate causal effect population subgroupaverage population distribution subgroupsIn conditionally randomized experiments, standardization essential yield unbiased estimates population average causal effect. strategy also essential observational studies discuss soon.end class, able todescribe different ways quantitatively measure causal effectestimate average causal effect using data conditionally randomized experiment","code":""},{"path":"exchangeability-and-experiments.html","id":"lab-analyze-a-randomized-experiment","chapter":"2 Exchangeability and experiments","heading":"2.5 Lab: Analyze a randomized experiment","text":"Sep 6. Link Materials.Link SolutionsThis lab use R analyze data randomized experiment households randomized receive mailers encouraging vote, researchers examined effects voter turnout (Gerber, Green, & Larimer 2008).","code":""},{"path":"exchangeability-and-experiments.html","id":"inverse-probability-weighting","chapter":"2 Exchangeability and experiments","heading":"2.6 Inverse probability weighting","text":"Sep 7. Slides. class, read Hernán Robins 2020 Chapter 2.4, 3.1, 3.2.class introduce inverse probability weighting approach estimate average causal effects conditional exchangeability holds.","code":""},{"path":"consistency-and-positivity.html","id":"consistency-and-positivity","chapter":"3 Consistency and positivity","heading":"3 Consistency and positivity","text":"","code":""},{"path":"consistency-and-positivity.html","id":"asking-good-causal-questions","chapter":"3 Consistency and positivity","heading":"3.1 Asking good causal questions","text":"Sep 12. Slides. class, read Hernán Robins 2020 Chapter 3. Optionally, read Hernán 2016.Good causal questions structured credibility strong two key assumptions: positivity consistency.Positivity. Every population subgroup receives every treatment value non-zero probabilityConsistency. Potential outcomes \\(Y^\\) well-defined linked observable dataAfter class, ready discussion lab related common violation consistency assumption one unit’s treatment affects another unit’s outcome.","code":""},{"path":"consistency-and-positivity.html","id":"lab-interference","chapter":"3 Consistency and positivity","heading":"3.2 Lab: Interference","text":"Sep 13 Slides.defining causal effects, often discuss outcome \\(Y^\\) person realize exposed treatment value \\(\\). definitions become harder exists interference: outcome unit \\(\\) depends treatment assigned unit \\(j\\). discussion focus understanding interference need update potential outcomes notation interference present.","code":""},{"path":"directed-acyclic-graphs.html","id":"directed-acyclic-graphs","chapter":"4 Directed Acyclic Graphs","heading":"4 Directed Acyclic Graphs","text":"","code":""},{"path":"directed-acyclic-graphs.html","id":"marginal-independence","chapter":"4 Directed Acyclic Graphs","heading":"4.1 Marginal independence","text":"Sep 14. Slides. class, read Hernán Robins 2020 Chapter 6.1 6.2. historical reference, optionally see Greenland, Pearl, Robins 1999.class introduce key ideas DAGs.Directed Acyclic Graph. series nodes representing variables, connected directed edges representing direct causal effects. node edge least two nodes must drawn graph.Path. path sequence edges connecting two nodesCollider along path. node \\(B\\) directed edges collide: \\(\\rightarrow B \\leftarrow C\\). collider blocks path.DAGs help us know variables \\(\\) \\(B\\) statistically related\\(\\) \\(B\\) marginally dependent exists unblocked path connecting \\(\\) \\(B\\) marginally independent paths connecting blocked","code":""},{"path":"directed-acyclic-graphs.html","id":"conditional-independence","chapter":"4 Directed Acyclic Graphs","heading":"4.2 Conditional independence","text":"Sep 19. Slides. class, read Hernán Robins 2020 Chapter 6.3 6.4, especially Fine Point 6.1 page abbreviation.Often, want condition set variables \\(\\vec{L}\\) conditional exchangeability holds.path blocked node path blocked. every node path open, entire path openA non-collider blocked conditioned , otherwise openA collider open descendants conditioned . Otherwise blocked","code":""},{"path":"directed-acyclic-graphs.html","id":"lab-dags-review-and-causal-discovery","chapter":"4 Directed Acyclic Graphs","heading":"4.3 Lab: DAGs Review and Causal discovery","text":"Sep 20. Slides. class, read Hernán Robins 2020 Fine Point 6.3.lab, ’re reviewing DAG basics identifying paths determining whether path open closed. ’ll also talk bit causal discovery practice creating DAGs data.","code":""},{"path":"directed-acyclic-graphs.html","id":"sufficient-adjustment-sets","chapter":"4 Directed Acyclic Graphs","heading":"4.4 Sufficient adjustment sets","text":"Sep 21. Slides. class, read Hernán Robins 2020 7.1–7.4.marginal exchangeability hold, may able condition set variables \\(\\vec{L}\\) conditional exchangeability holds. can accomplish blocking non-causal paths \\(\\) \\(Y\\). set called sufficient adjustment set. find sufficient adjustment set, use backdoor criterion:set \\(L\\) blocks backdoor pathsThe set \\(L\\) contain descendants \\(\\)","code":""},{"path":"statistical-modeling.html","id":"statistical-modeling","chapter":"5 Statistical modeling","heading":"5 Statistical modeling","text":"","code":""},{"path":"statistical-modeling.html","id":"why-model","chapter":"5 Statistical modeling","heading":"5.1 Why model?","text":"Sep 26. Slides. class, read Hernán Robins 2020 Chapter 11.point, used statistical models. Instead, havetaken means within subgroupsthen aggregated subgroupsToday discuss strategy breaks many confounding variables, thus many subgroups.","code":""},{"path":"statistical-modeling.html","id":"lab-parametric-g-formula","chapter":"5 Statistical modeling","heading":"5.2 Lab: Parametric g-formula","text":"Sep 27. Download corresponding R Markdown file .discussion, make sure download data ’ll using. See Ed Discussion post detail.class, read Hernán Robins 2020 Chapter 13 15.1.Solutions lab exercise slides","code":""},{"path":"statistical-modeling.html","id":"inverse-probability-of-treatment-weighting","chapter":"5 Statistical modeling","heading":"5.3 Inverse probability of treatment weighting","text":"Sep 28. Slides. Reading: class, read Hernán Robins 2020 Chapter 12.1–12.5.Today introduce estimate causal effects modeling probability treatment, also known propensity score.","code":""},{"path":"statistical-modeling.html","id":"matching","chapter":"5 Statistical modeling","heading":"5.4 Matching","text":"Oct 3. Slides. class, read Hernán Robins 2020 Chapter 15.2.Today introduce idea matching allows us estimate average treatment treated.","code":""},{"path":"statistical-modeling.html","id":"lab-matching-in-r","chapter":"5 Statistical modeling","heading":"5.5 Lab: Matching in R","text":"Oct 4. Slides. R Markdown.lab, ’ll go distance metrics matching multiple covariates. ’ll also go examples using R matching estimate causal effects.","code":""},{"path":"statistical-modeling.html","id":"discussion-of-matching","chapter":"5 Statistical modeling","heading":"5.6 Discussion of matching","text":"Oct 5 Slides. R Markdown.’ll wrap discussion matching introducing propensity score matching coarsened exact matching. ’ll also discuss combining regression matching methods estimate causal effects.","code":""},{"path":"statistical-modeling.html","id":"lab-final-project-hw4-qa","chapter":"5 Statistical modeling","heading":"5.7 Lab: Final Project + HW4 Q&A","text":"Oct 10 SlidesWe’ll talk final project!","code":""},{"path":"statistical-modeling.html","id":"worked-example-of-statistical-modeling","chapter":"5 Statistical modeling","heading":"5.8 Worked example of statistical modeling","text":"section presents math code worked example statistical\nmodeling, includingoutcome modelinginverse probability treatment weightingmatchingWe use methods answer causal question:degree completing 4-year college degree age 25\nincrease probability college-educated spouse \nresidential partner age 35?theory motivates question follows. College causes\npeople personally higher earnings. also affects \nprobability someone lives high-earning partner. college\ndegree thus affects household incomes effect \nindividual earnings also effect individuals pool\nhouseholds.","code":""},{"path":"statistical-modeling.html","id":"data-access","chapter":"5 Statistical modeling","heading":"5.8.1 Data access","text":"prepared data study question. need \ndownload data directly data distributor National\nLongitudinal Survey Youth 1997\ncohort. .First, download two supporting files us:nlsy97.NLSY97\ntagset file containing variable namesprepare_nlsy97.R\nR script prepare dataput files directory workNext, download data NLSY97.register surveylog NLS Investigatorchoose NLSY97 studyupload tagset downloaded usdownload data. , change file name default\nnlsy97unzip file. Find nlsy97.dat unzipped folderdrag file folder workIn R console, run line code belowAfter following steps, data working directory! \ncan load data quickly future typingWhy can’t just send data? Two reasons!NLSY97 created procedure register users encourage\nethical use data researchBy registering, help Bureau Labor Statistics know \nmany people using data, helpful demonstrating\nwide use data useful securing funding \nfuture surveys!","code":"\ninstall.packages(\"tidyverse\") # if you do not have it yet\ninstall.packages(\"Amelia\")    # if you do not have it yet\nsource(\"prepare_nlsy97.R\")\nlibrary(tidyverse)\nd <- readRDS(\"d.RDS\")"},{"path":"statistical-modeling.html","id":"worked-example-outcome-modeling","chapter":"5 Statistical modeling","heading":"5.8.2 Worked example: Outcome modeling","text":"Outcome modeling based following identification result, \ntranslates causal quantity statistical estimand \ninvolve counterfactual outcomes.\\[\\begin{aligned}\n&E(Y^) \\\\\n&\\text{law iterated expectation,}\\\\\n&= E(E(Y^\\mid \\vec{L})) \\\\\n&\\text{exchangeability,}\\\\\n&= E(E(Y^\\mid \\vec{L}, = )) \\\\\n&\\text{consistency,}\\\\\n&= E(E(Y\\mid \\vec{L}, = ))\n\\end{aligned}\\]use sample mean estimator outer expectation, \ndiscuss several estimators inner conditional\nexpectation. \\[\\begin{aligned}\n\\hat{E}(Y^) &= \\frac{1}{n}\\sum_{=1}^n \\hat{E}(Y\\mid \\vec{L} = \\vec\\ell_i, = )\n\\end{aligned}\\]Now intuition: estimator tells tofor unit \\(\\) sample, estimate expected outcome among\npeople look like unit (\\(\\vec{L} = \\vec\\ell_i\\)) got\ntreatment value interest \\(= \\).take average estimate unitsA nonparametric strategy step (1) literally estimate \nexpected outcome taking sample average among units \nidentical unit \\(\\) along confounders \\(\\vec{L}\\). \nmany confounding variables units, might zero\ncases! parametric strategy assume model outcome,\n\\[E(Y\\mid \\vec{L} = \\vec\\ell, = ) = \\alpha + \\beta + \\vec\\ell'\\vec\\gamma\\]\nparameters \\(\\{\\alpha,\\beta,\\vec\\gamma\\}\\) estimated \nOrdinary Least Squares regression.Note: model like! example, add\ninteractions use logistic regression instead.model, want predict expected outcome \ntreatment value \\(\\) every unit unit’s observed confounder\nvalues.\\[\\hat{E}(Y\\mid \\vec{L} = \\vec\\ell_i, = ) = \\hat\\alpha + \\hat\\beta + \\vec\\ell'_i\\hat{\\vec\\gamma}\\]\ncode, wouldmodify every unit’s treatment value \\(\\)\nintuition: actually intervened treatment \nworld, value treatment change values \n\\(\\vec{L}\\) remain unchanged\nintuition: actually intervened treatment \nworld, value treatment change values \n\\(\\vec{L}\\) remain unchangedpredict outcome every unitaverage sampleIn code , estimated three causal quantities\\(E(Y^1)\\), probability respondent \ncollege-educated spouse partner intervened assign \ncollege degree \\(E(Y^0)\\), probability respondent \ncollege-educated spouse partner intervened assign \ncollege degree \\(E(Y^1-Y^0)\\), average causal effect college degree \nspouse partner college degree","code":"\noutcome_model <- lm(y ~ a + sex + race + \n                      mom_educ + dad_educ + \n                      log_parent_income +\n                      log_parent_wealth +\n                      test_percentile,\n                    data = d)\n# Make data where all are treated\nd_if_treated <- d %>%\n  mutate(a = \"college\")\n# Make data where all are untreated\nd_if_untreated <- d %>%\n  mutate(a = \"no_college\")\npredicted_outcome <- d %>%\n  mutate(yhat1 = predict(outcome_model,\n                         newdata = d_if_treated),\n         yhat0 = predict(outcome_model,\n                         newdata = d_if_untreated))\npredicted_outcome %>%\n  summarize(average_yhat1 = mean(yhat1),\n            average_yhat0 = mean(yhat0),\n            average_effect = mean(yhat1 - yhat0))## # A tibble: 1 × 3\n##   average_yhat1 average_yhat0 average_effect\n##           <dbl>         <dbl>          <dbl>\n## 1         0.427         0.164          0.263"},{"path":"statistical-modeling.html","id":"worked-example-treatment-modeling","chapter":"5 Statistical modeling","heading":"5.8.3 Worked example: Treatment modeling","text":"Using different identification result, can also proceed \nparametric model treatment instead outcome. \nstrategy, population mean outcome \\(E(Y^)\\) treatment \\(\\)\nequals weighted average units observed treatment,\nweighted weight equalswhen \\(= \\), inverse probability treatmentwhen \\(\\neq \\), zeroBelow identification proof inverse probability treatment\nweighting.math complicated, intuition simpler: \nweighting, create pseudo-population treatment \\(\\) \nindependent confounders \\(\\vec{L}\\). , need know\npropensity score: probability observed treatment value\ngiven confounders.identification result points toward inverse probability \ntreatment weighting estimator known Horvitz-Thompson estimator,\n\\[\\hat{E}(Y^) = \\frac{1}{n}\\sum_{=1}^n \\frac{Y_i\\mathbb{}(A_i=)}{\\hat{P}(= \\mid\\vec{L} = \\vec\\ell_i)}\\]\nrelated estimator often used Hajek estimator, \nnormalizes weights sum 1.\n\\[\\hat{E}(Y^) = \\frac{1}{\\sum_{=1}^n\\frac{\\mathbb{}(A_i=)}{\\hat{P}(= \\mid \\vec{L} = \\vec\\ell_i)}}\\sum_{=1}^n \\frac{Y_i\\mathbb{}(A_i=)}{\\hat{P}(= \\mid\\vec{L} = \\vec\\ell_i)}\\]code, wouldestimate model probability treatment given confounders,\nexample logistic regressionfor every unit, predict probability \\(= \\text{College}\\)estimate probability treatment observedfor went college, equals p_collegefor , equals 1 - p_collegeThis quantity often called propensity score. encapsulates\ninformation contained confounders probability \ntreatment.estimate mean outcomes among treatment, weighted \ninverse propensity score. actually two ways \n.Horvitz-Thompson estimator relies fact true\npropensity scores sum number observationsthe Hajek estimator uses weighted mean, thus normalizing weights\nsum 1While asymptotically valid, finite-sample reasons \nprefer second estimator (Hajek).","code":"\ntreatment_model <- glm(I(a == \"college\") ~ \n                         sex + race + \n                         mom_educ + dad_educ + \n                         log_parent_income +\n                         log_parent_wealth +\n                         test_percentile,\n                       data = d,\n                       family = binomial)\npredicted_p_college <- d %>%\n  mutate(p_college = predict(treatment_model,\n                             # the line below tells R\n                             # to predict a probability\n                             # rather than log odds\n                             type = \"response\"))\npredicted_p_scores <- predicted_p_college %>%\n  mutate(propensity_score = case_when(\n    a == \"college\" ~ p_college,\n    a == \"no_college\" ~ 1 - p_college\n  ))\npredicted_p_scores %>%\n  summarize(y1 = mean(y * I(a == \"college\") / propensity_score),\n            y0 = mean(y * I(a == \"no_college\") / propensity_score))## # A tibble: 1 × 2\n##      y1    y0\n##   <dbl> <dbl>\n## 1 0.374 0.164\npredicted_p_scores %>%\n  group_by(a) %>%\n  summarize(estimate = weighted.mean(y, w = 1 / propensity_score))## # A tibble: 2 × 2\n##   a          estimate\n##   <chr>         <dbl>\n## 1 college       0.401\n## 2 no_college    0.163"},{"path":"statistical-modeling.html","id":"worked-example-matching","chapter":"5 Statistical modeling","heading":"5.8.4 Worked example: Matching","text":"also estimate matching. Matching can interpreted \noutcome modeling strategy conditional mean outcome\n\\(E(Y\\mid\\vec{} = , \\vec{L} = \\vec\\ell_i)\\) estimated mean\noutcome among set units whose confounder values similar \nunit \\(\\) received treatment value \\(\\) interest.One way defining ``similar’’ propensity score matching: find\nunits whose probability treatment given confounders close \nprobability unit \\(\\). example, code ,estimates probability college completion using logistic\nregressionfor person finished college, matches non-college\ngraduate whose probability completing college similarThe variable matched$weights one element person \ndataset. indicates many times person appears matched\nsample. are1,533 college graduates weight 11,533 matched non-graduates weight 14,705 non-matched non-graudates weight 0Within matched data, non-graduates graduates similar\nalong confounding variables. estimatethe probability college educated spouse among college\ngraduates mean among peoplethe probability persisted \nfinished college, mean among matched counterpartsAn even better estimator might use linear regression adjust \ndifferences within matched pairs exist matches \nidentical., predict potential outcoems matched fit report \nexpected outcome among college graduates factual treatment\nunderThese results suggest completing college increases probability\ncollege-educated spouse partner 27 percentage\npoints.","code":"\nlibrary(MatchIt)\nmatched <- matchit(a == \"college\" ~ sex + race + mom_educ + \n                     dad_educ + log_parent_income + \n                     log_parent_wealth + test_percentile,\n                   method = \"nearest\", \n                   distance = \"glm\",\n                   estimand = \"ATT\",\n                   data = d)\ntable(d$a,matched$weights)##             \n##                 0    1\n##   college       0 1533\n##   no_college 4705 1533\nd %>%\n  mutate(weight = matched$weights) %>%\n  group_by(a) %>%\n  summarize(p_spouse_college = weighted.mean(y, w = weight))## # A tibble: 2 × 2\n##   a          p_spouse_college\n##   <chr>                 <dbl>\n## 1 college               0.528\n## 2 no_college            0.232\nmatched_fit <- lm(y ~ a*(sex + race + mom_educ + \n                           dad_educ + log_parent_income + \n                           log_parent_wealth + test_percentile), \n                  data = d, \n                  weights = matched$weights)\n# Create data frames for prediction\ncollege_grads_factual <- d %>%\n  filter(a == \"college\")\ncollege_grads_counterfactual <- college_grads_factual %>%\n  mutate(a = \"no_college\")\n\n# Predict outcomes from the model\ncollege_grads_factual %>%\n  mutate(yhat_college = predict(matched_fit, \n                                newdata = college_grads_factual),\n         yhat_no_college = predict(matched_fit,\n                                   newdata = college_grads_counterfactual)) %>%\n  # Report estimated average outcomes\n  select(starts_with(\"yhat\")) %>%\n  summarize_all(.funs = mean) %>%\n  # Estimate the causal effect\n  mutate(effect = yhat_college - yhat_no_college)## # A tibble: 1 × 3\n##   yhat_college yhat_no_college effect\n##          <dbl>           <dbl>  <dbl>\n## 1        0.528           0.259  0.269"},{"path":"front-door.html","id":"front-door","chapter":"6 Front door","heading":"6 Front door","text":"Oct 12. Slides. class, read Hernán Robins 2020 Technical Point 7.4. Optionally, see Glynn Kashin 2018This lecture engage new methods causal identification beyond backdoor adjustment. learning goals generalengage new causal identification approachtranslate method codecritique identification assumptionsFront door methods causal identification one case use show building blocks already know prepared learn new approaches causal identification.","code":""},{"path":"front-door.html","id":"identification","chapter":"6 Front door","heading":"Identification","text":"focus simplest case front door identification, depicted DAG variables \\(\\), \\(M\\), \\(Y\\) binary.setting, slides show following identification result.\\[P(Y^)=\\sum_m P(M = m\\mid = ) \\sum_{'}P(= ')P(Y\\mid M = m, = ')\\]","code":""},{"path":"front-door.html","id":"code-example","chapter":"6 Front door","heading":"Code example","text":"lecture slides translate method code one simulated example. providing code make easy copy follow along.Examine descriptive relationship \\(\\) \\(Y\\).Estimate probability \\(M\\) given \\(\\). causal assumptions, corresponds expected value \\(M\\) assignment value \\(\\) since \\(M\\rightarrow \\) unconfounded.Within front-door identification formula, need marginal probability treatment value.also need outcome distribution given \\(M\\) \\(\\).Given , can use backdoor adjustment identify outcome intervention \\(M\\) backdoor adjustment \\(\\).Bringing together, front-door identification.","code":"\nlibrary(tidyverse)\nsim_data <- function(n = 100) {\n  data.frame(U = runif(n)) %>%\n    # Generate a binary treatment\n    mutate(A = rbinom(n(), \n                      prob = U, \n                      size = 1)) %>%\n    # Generate a binary mediator\n    mutate(M = rbinom(n(), \n                      prob = .1 + .8*A, \n                      size = 1)) %>%\n    # Generate a binary outcome\n    mutate(Y = rbinom(n(), \n                      prob = plogis(U + .5*M), \n                      size = 1))\n}\ndata <- sim_data(n = 10e3)\ndata %>%\n  group_by(A) %>%\n  summarize(Y = mean(Y))## # A tibble: 2 × 2\n##       A     Y\n##   <int> <dbl>\n## 1     0 0.601\n## 2     1 0.754\np_M_given_A <- data %>%\n  # Count size of each group\n  group_by(A, M) %>%\n  count() %>%\n  # Convert to probability within A\n  group_by(A) %>%\n  mutate(p_M_under_A = n / sum(n)) %>%\n  select(A,M,p_M_under_A) %>%\n  print()## # A tibble: 4 × 3\n## # Groups:   A [2]\n##       A     M p_M_under_A\n##   <int> <int>       <dbl>\n## 1     0     0      0.901 \n## 2     0     1      0.0987\n## 3     1     0      0.0921\n## 4     1     1      0.908\n# Probability of each A\np_A <- data %>%\n  # Count size of each group\n  group_by(A) %>%\n  count() %>%\n  # Convert to probability\n  ungroup() %>%\n  mutate(p_A = n / sum(n)) %>%\n  select(A,p_A) %>%\n  print()## # A tibble: 2 × 2\n##       A   p_A\n##   <int> <dbl>\n## 1     0 0.500\n## 2     1 0.500\n# Probability of Y = 1 given M and A\np_Y_given_M_A <- data %>%\n  group_by(A,M) %>%\n  summarize(P_Y_given_A_M = mean(Y),\n            .groups = \"drop\") %>%\n  print()## # A tibble: 4 × 3\n##       A     M P_Y_given_A_M\n##   <int> <int>         <dbl>\n## 1     0     0         0.590\n## 2     0     1         0.702\n## 3     1     0         0.638\n## 4     1     1         0.766\n# Probability of Y = 1 under intervention on M\np_Y_under_M <- p_Y_given_M_A %>%\n  left_join(p_A, by = \"A\") %>%\n  group_by(M) %>%\n  summarize(p_Y_under_M = sum(P_Y_given_A_M  * p_A)) %>%\n  print()## # A tibble: 2 × 2\n##       M p_Y_under_M\n##   <int>       <dbl>\n## 1     0       0.614\n## 2     1       0.734\n# Probability of Y = 1 under intervention on A\np_Y_under_A <- p_M_given_A %>%\n  left_join(p_Y_under_M,\n            by = \"M\") %>%\n  group_by(A) %>%\n  summarize(estimate = sum(p_M_under_A * p_Y_under_M)) %>%\n  print()## # A tibble: 2 × 2\n##       A estimate\n##   <int>    <dbl>\n## 1     0    0.626\n## 2     1    0.723"},{"path":"instrumental-variables.html","id":"instrumental-variables","chapter":"7 Instrumental variables","heading":"7 Instrumental variables","text":"","code":""},{"path":"instrumental-variables.html","id":"experimental-settings","chapter":"7 Instrumental variables","heading":"7.1 Experimental settings","text":"Oct 17. Slides.instrumental variable (IV) identification strategy applies treatment effect \\(\\) \\(Y\\) confounded unobserved variables (\\(U\\)), instrument \\(Z\\) creates random unconfounded variation \\(\\).clean setting IV randomized experiments non-compliance: experimenter randomizes assigned treatment (\\(Z\\)) actual treatment (\\(\\)) may unequal \\(Z\\) units follow assignment. first class discuss setting.","code":""},{"path":"instrumental-variables.html","id":"observational-settings","chapter":"7 Instrumental variables","heading":"7.2 Observational settings","text":"Oct 19 Slides. class, read Hernán Robins 2020 Chapter 16.Thursday, move IV analysis observational settings. focus casual assumptions required IV. assumptions often hold design experiments non-compliance. observational settings, can doubtful.","code":""},{"path":"instrumental-variables.html","id":"lab-estimation","chapter":"7 Instrumental variables","heading":"7.3 Lab: Estimation","text":"lab, two lectures, implement instrumental variables estimators R. put instructions accessing dataset, now code generates simulated data.","code":"\nlibrary(tidyverse)\niv_data <- data.frame(Z = rbinom(1e3,1,.5)) %>%\n  mutate(U = rnorm(n()),\n         p_A = plogis(-.5 + Z + U),\n         A = rbinom(n(), 1, p_A),\n         Y = rnorm(n(), U + A)) %>%\n  select(-p_A)"},{"path":"instrumental-variables.html","id":"wald-estimator","chapter":"7 Instrumental variables","heading":"7.3.1 Wald estimator","text":"Wald estimator proceeds (1) estimating effect instrument outcome, (2) estimating effect instrument treatment, (3) dividing (1) / (2).\n\\[\\begin{aligned}\n\\hat{E}(Y^{=1}-Y^{=0}) &= \\frac{\\hat{E}(Y^{z=1}-Y^{z=0})}{\\hat{E}(^{z=1}-^{z=0})}\\\\\n&= \\frac{\\hat{E}(Y\\mid Z = 1) - \\hat{E}(Y\\mid Z = 0)}{\\hat{E}(\\mid Z = 1) - \\hat{E}(\\mid Z = 0)}\n\\end{aligned}\\]Implement Wald estimator code.Estimate mean difference \\(Y\\) groups defined \\(Z\\)Estimate mean difference \\(\\) groups defined \\(Z\\)Divide (1) / (2)","code":""},{"path":"instrumental-variables.html","id":"two-stage-least-squares","chapter":"7 Instrumental variables","heading":"7.3.2 Two-stage least squares","text":"second estimator IV two-stage least squares.Use OLS model \\(\\) function \\(Z\\)Store predicted values \\(\\hat{}\\) without modifying \\(Z\\)Use OLS model \\(Y\\) function \\(\\hat{}\\)coefficient \\(\\hat{}\\) (3) estimates effect \\(\\) \\(Y\\).","code":""},{"path":"regression-discontinuity.html","id":"regression-discontinuity","chapter":"8 Regression discontinuity","heading":"8 Regression discontinuity","text":"","code":""},{"path":"regression-discontinuity.html","id":"introduction","chapter":"8 Regression discontinuity","heading":"8.1 Introduction","text":"Oct 24","code":""},{"path":"regression-discontinuity.html","id":"lab","chapter":"8 Regression discontinuity","heading":"8.2 Lab","text":"Oct 25","code":""},{"path":"regression-discontinuity.html","id":"discussion","chapter":"8 Regression discontinuity","heading":"8.3 Discussion","text":"Oct 26","code":""},{"path":"difference-in-difference.html","id":"difference-in-difference","chapter":"9 Difference in difference","heading":"9 Difference in difference","text":"","code":""},{"path":"difference-in-difference.html","id":"introduction-1","chapter":"9 Difference in difference","heading":"9.1 Introduction","text":"Oct 31","code":""},{"path":"difference-in-difference.html","id":"lab-1","chapter":"9 Difference in difference","heading":"9.2 Lab","text":"Nov 1","code":""},{"path":"difference-in-difference.html","id":"discussion-1","chapter":"9 Difference in difference","heading":"9.3 Discussion","text":"Nov 2","code":""},{"path":"synthetic-control.html","id":"synthetic-control","chapter":"10 Synthetic control","heading":"10 Synthetic control","text":"","code":""},{"path":"synthetic-control.html","id":"introduction-2","chapter":"10 Synthetic control","heading":"10.1 Introduction","text":"Nov 7","code":""},{"path":"synthetic-control.html","id":"lab-2","chapter":"10 Synthetic control","heading":"10.2 Lab","text":"Nov 8","code":""},{"path":"synthetic-control.html","id":"discussion-2","chapter":"10 Synthetic control","heading":"10.3 Discussion","text":"Nov 9","code":""},{"path":"data-driven-methods.html","id":"data-driven-methods","chapter":"11 Data-driven methods","heading":"11 Data-driven methods","text":"","code":""},{"path":"data-driven-methods.html","id":"machine-learning-to-target-human-attention","chapter":"11 Data-driven methods","heading":"11.1 Machine learning to target human attention","text":"Nov 14","code":""},{"path":"data-driven-methods.html","id":"lab-3","chapter":"11 Data-driven methods","heading":"11.2 Lab","text":"Nov 15","code":""},{"path":"data-driven-methods.html","id":"discussion-of-machine-learning","chapter":"11 Data-driven methods","heading":"11.3 Discussion of machine learning","text":"Nov 16","code":""},{"path":"current-research.html","id":"current-research","chapter":"12 Current research","heading":"12 Current research","text":"","code":""},{"path":"current-research.html","id":"research-discussion-sam","chapter":"12 Current research","heading":"12.1 Research discussion: Sam","text":"Nov 21","code":""},{"path":"current-research.html","id":"research-discussion-ian","chapter":"12 Current research","heading":"12.2 Research discussion: Ian","text":"Nov 28","code":""},{"path":"current-research.html","id":"lab-group-presentations","chapter":"12 Current research","heading":"12.3 Lab: Group presentations","text":"Nov 29","code":""},{"path":"course-recap.html","id":"course-recap","chapter":"13 Course recap","heading":"13 Course recap","text":"Nov 30We review learned semester.","code":""},{"path":"discussion-2.-stats-review.html","id":"discussion-2.-stats-review","chapter":"Discussion 2. Stats review","heading":"Discussion 2. Stats review","text":"SlidesTo execute simulations locally, download .Rmd ","code":"\nlibrary(ggplot2)\nlibrary(ggmosaic)\nlibrary(tibble)"},{"path":"discussion-2.-stats-review.html","id":"sample-expectations-converge-to-population","chapter":"Discussion 2. Stats review","heading":"13.1 Sample expectations converge to population","text":"can generate simulations show sample mean variance converge \npopulation values.","code":"\ntrue_mean <- 2\ntrue_var <- 5\n\nsample_mean_seq <- 1:3000\nsample_means <- vapply(\n  sample_mean_seq,\n  \\(x) mean(rnorm(n = x, mean = true_mean, sd = sqrt(true_var))),\n  numeric(1)\n)\nsample_variances <- vapply(\n  sample_mean_seq,\n  \\(x) {\n    data <- rnorm(n = x, mean = true_mean, sd = sqrt(true_var))\n    sample_mean <- mean(data)\n    sum((data - sample_mean)^2)/length(data)\n  },\n  numeric(1)\n)\n\nmeans <- tibble(\"N\" = sample_mean_seq, \"Sample Mean\" = sample_means)\nvars <- tibble(\"N\" = sample_mean_seq, \"Sample Variance\" = sample_variances)\n\ncolors <- c(\"Sample Mean\" = \"lightblue\", \"Population Mean\" = \"red\")\n\nggplot(means, aes(y = `Sample Mean`, x = N)) +\n  geom_line(color = \"lightblue\") +\n  geom_abline(slope = 0, intercept = true_mean, color = \"red\") +\n  theme_bw()\nggplot(vars, aes(y = `Sample Variance`, x = N)) +\n  geom_line(color = \"lightblue\") +\n  geom_abline(slope = 0, intercept = true_var, color = \"red\") +\n  theme_bw()"},{"path":"discussion-2.-stats-review.html","id":"simulate-conditional-expectations","chapter":"Discussion 2. Stats review","heading":"13.2 Simulate conditional expectations","text":"Simulate conditional expectations within groups differ sample\nmean.","code":"\ngroup1_means <- rnorm(100, mean = 20, sd = 5)\ngroup2_means <- rnorm(100, mean = 30, sd = 5)\ngroup_means <- data.frame(\n  \"Group\" = c(rep(\"Group 1\", 100), rep(\"Group 2\", 100)),\n  \"Values\" = c(group1_means, group2_means),\n  \"x\" = rnorm(200, 5, sd = 3)\n)\nggplot(group_means, aes(x = x, y = Values, color = Group)) +\n  geom_point() +\n  geom_abline(\n    slope = 0,\n    intercept = mean(group_means$Values),\n    show.legend = TRUE,\n    color = \"gray30\"\n  ) +\n  geom_abline(\n    slope = 0,\n    intercept = mean(group_means[group_means$Group == \"Group 1\", ]$Values),\n    show.legend = TRUE,\n    color = \"#F8766D\"\n  ) +\n  geom_abline(\n    slope = 0,\n    intercept = mean(group_means[group_means$Group == \"Group 2\", ]$Values),\n    show.legend = TRUE,\n    color = \"#00BFC4\"\n  ) +\n  theme_bw()"},{"path":"discussion-2.-stats-review.html","id":"show-independence-of-variables---example-of-two-dice-rolling","chapter":"Discussion 2. Stats review","heading":"13.3 Show independence of variables - example of two dice rolling","text":"","code":"\ndice_1 <- sample(1:6, 100000, replace = TRUE)\ndice_2 <- sample(1:6, 100000, replace = TRUE)\ndice <- tibble(\n  \"dice\" = c(rep(\"Die 1\", 100000), rep(\"Die 2\", 100000)),\n  \"value\" = c(dice_1, dice_2)\n)\n\nggplot(data = dice) +\n  geom_mosaic(aes(x = product(dice, value), fill = dice)) +   \n  labs(y=\"\", x=\"Value Rolled\", title = \"Independence of dice roll\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"discussion-3.-analyzing-an-experiment-in-r","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"Discussion 3. Analyzing an Experiment in R","text":"Slides","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"download-.rmd-document","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.4 Download .Rmd Document","text":"Download today’s .Rmd document .","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"get-out-and-vote-experiment","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.5 Get out and Vote Experiment","text":"lab, explore experiment digs mechanisms\nunderlying people vote. exercise based :Gerber, Alan S., Donald P. Green, Christopher W. Larimer. “Social Pressure Voter Turnout: Evidence Large-scale Field Experiment.” American Political Science Review 102.1 (2008): 33-48.long-standing theory many people\nvote driven social norms (e.g. understanding voting\ncivic duty). theory, dominant theoretical\nexplanation, little empirical backing long time. experiment\nexamines theory asking question:\nextent social norms cause voter turnout?","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"experimental-design","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.5.1 Experimental Design","text":"order answer question, approximately 80,000 Michigan households\nrandomly assigned treatment control groups, treatment\ngroup randomly assigned one four possible treatment arms. \ntreatment arms varied intensity social pressure conveyed,\ndefined follows:first treatment arm mailed letter simply reminded \nvoting civic duty.second treatment arm mailed letter telling researchers\nstudying voting turnout based public records.third treatment arm mailed letter stating voting turnout\nrevealed members household.fourth treatment arm mailed letter stating voting turnout\nrevealed household neighbors.","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"analyze-experiment","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6 Analyze Experiment","text":"Download RMarkdown file .","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"necessary-packages","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.1 Necessary packages","text":"Note: errors probably either don’t dplyr haven\ninstalled.","code":"\nlibrary(dplyr)\nlibrary(haven)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"import-data","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.2 Import data","text":"Alternatively (really want), download data load directly computer. Make sure save data directory RMarkdown file .\ncan can import data :gotv <- read_dta(\"social_pressure.dta\")Run following code get quick peek dataset using function glimpse. returns info number rows/columns, column names, type data column. Notice information year birth yob explicitly age. Also notice treatments labeled numbers 0 4.","code":"\ngotv <- read_dta(\"https://causal3900.github.io/assets/data/social_pressure.dta\")\nglimpse(gotv)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"clean-data","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.3 Clean data","text":"First, let’s construct age variable describing old (number years)\nperson year 2006. yob variable says year person\nborn . , use mutate function, can read .Given person’s year birth, calculate age year 2006? Note can arithmetic operations information dataset. example, two columns col_1 col_2 wanted create third column called col_3 sum two columns, write:mutate(col_3 = col_1 + col_2)code started . Fill appropriate expression age = add column gotv labeled age contains old person 2006.Now, convert treatment variable ’s numeric representation \ncorresponding labels are0: “Control”1: “Hawthorne” (‘researchers viewing records via public data’ treatment arm)2: “Civic Duty” (‘voting civic duty’ treatment arm)3: “Neighbors” (‘voting turnout revealed neighbors’ treatment arm)4: “Self” (‘voting turnout revealed household’ treatment arm), want use function case_when described .\ngeneral syntax case_when(condition ~ output-value)example, condition treatement == 0 output value \"Control\". search every value treatment column equals 0 replace string \"Control\".started code . Decide argument(s) pass inside parantheses case_when().Now, use glimpse see added age variable treatments word instead number labels.","code":"\ngotv <- gotv |>\n  mutate(age = )\ngotv <- gotv |>\n  mutate(treatment = case_when()) \nglimpse(gotv)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"balance-table","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.4 Balance table","text":"Next, ’re going confirm control treatment groups look pretty\nmuch across set covariates, .e. two groups balanced covariates. Specifically means ’re going calculate mean value set covariates across treatment/control\narms, expect pretty much equal randomization worked. related idea exchangeability.exercise, going reproduce table similar Table 1 paper. want table shows mean value following covariates five treatment arms: Household size, Nov 2002, Nov 2000, Aug 2004, Aug 2002, Aug 2000, Female, Age (years). create table 5 rows, one treatment arm, 8 columns, one covariate interest.started code . need :Pass argument group_by() calculate seperate means treatment arm.\nLook documentation group_by function.\nLook documentation group_by function.Pass argument summarise() computes mean covariate covariates seperate treatment arm.\nLook documentation summarise function.\nmay find function across useful well. can use function inside summarise()!\nLook documentation summarise function.may find function across useful well. can use function inside summarise()!Note numbers match exactly Table 1. want notice values column similar across rows.","code":"\ncovariates <- c(\"sex\", \"age\", \"g2000\", \"g2002\", \"p2000\", \"p2002\", \"p2004\", \"hh_size\")\n\ngotv_balance <- gotv |>\n  group_by(...) |>\n  summarise(...)\n\nprint(gotv_balance)"},{"path":"discussion-3.-analyzing-an-experiment-in-r.html","id":"results","chapter":"Discussion 3. Analyzing an Experiment in R","heading":"13.6.5 Results","text":"Finally, let’s replicate final results (Table 2). treatment group, calculate percentage individuals got voted, well total number individuals group! started code . need toPass argument group_by() working treatment arm seperately (!)Pass two arguments summarise() following:\nCreate column titled Percentage_Voting contains percent group voted\nCreate column titled num_of_individuals contains total number people group\nCreate column titled Percentage_Voting contains percent group votedCreate column titled num_of_individuals contains total number people group","code":"\ngotv_results <- gotv |>\n  group_by(...) |>\n  summarise(...)\n\nprint(gotv_results)"},{"path":"discussion-3.-analyzing-an-experiment-in-r-solutions.html","id":"discussion-3.-analyzing-an-experiment-in-r-solutions","chapter":"Discussion 3. Analyzing an Experiment in R SOLUTIONS","heading":"Discussion 3. Analyzing an Experiment in R SOLUTIONS","text":"possible solutions exercises discussion. code may look different , long output matters!can download file .","code":""},{"path":"discussion-3.-analyzing-an-experiment-in-r-solutions.html","id":"necessary-packages-1","chapter":"Discussion 3. Analyzing an Experiment in R SOLUTIONS","heading":"13.7 Necessary packages","text":"Note: errors probably either don’t dplyr haven installed.","code":"\nlibrary(dplyr)\nlibrary(haven)"},{"path":"discussion-3.-analyzing-an-experiment-in-r-solutions.html","id":"import-data-1","chapter":"Discussion 3. Analyzing an Experiment in R SOLUTIONS","heading":"13.7.1 Import data","text":"","code":"\ngotv <- read_dta(\"https://causal3900.github.io/assets/data/social_pressure.dta\")\nglimpse(gotv)## Rows: 344,084\n## Columns: 16\n## $ sex           <dbl+lbl> 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,…\n## $ yob           <dbl> 1941, 1947, 1951, 1950, 1982, 1981, …\n## $ g2000         <dbl+lbl> 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,…\n## $ g2002         <dbl+lbl> 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,…\n## $ g2004         <dbl+lbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n## $ p2000         <dbl+lbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ p2002         <dbl+lbl> 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,…\n## $ p2004         <dbl+lbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,…\n## $ treatment     <dbl+lbl> 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0,…\n## $ cluster       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ voted         <dbl+lbl> 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,…\n## $ hh_id         <dbl> 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 5, 6, …\n## $ hh_size       <dbl> 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 1, 2, …\n## $ numberofnames <dbl> 21, 21, 21, 21, 21, 21, 21, 21, 21, …\n## $ p2004_mean    <dbl> 0.09523810, 0.09523810, 0.04761905, …\n## $ g2004_mean    <dbl> 0.8571429, 0.8571429, 0.8571429, 0.8…"},{"path":"discussion-3.-analyzing-an-experiment-in-r-solutions.html","id":"clean-data-1","chapter":"Discussion 3. Analyzing an Experiment in R SOLUTIONS","heading":"13.7.2 Clean data","text":"First, construct age variable describing old (number years) person year 2006. yob variable says year person born . > , use mutate function, can read .Fill appropriate expression age = add column gotv labeled age contains old person 2006.Now, convert treatment variable ’s numeric representation corresponding labels are0: “Control”1: “Hawthorne” (‘researchers viewing records via public data’ treatment arm)2: “Civic Duty” (‘voting civic duty’ treatment arm)3: “Neighbors” (‘voting turnout revealed neighbors’ treatment arm)4: “Self” (‘voting turnout revealed household’ treatment arm)One solution uses function case_when described .done differently. exercise, split task two pieces: create new column age gotv contains ages individual 2006, replace numeric treatment labels column treatment alphabetic/word labels. can actually one block code follows:Another alternative solution\nNow, use glimpse see added age variable treatments word instead number labels.Note, ways arrived ’s totally fine long results !","code":"\ngotv <- gotv |>\n  mutate(age = 2006 - yob)\ngotv <- gotv |>\n  mutate(treatment = case_when(\n      treatment == 0 ~ \"Control\",\n      treatment == 1 ~ \"Hawthorne\",\n      treatment == 2 ~ \"Civic Duty\",\n      treatment == 3 ~ \"Neighbors\",\n      treatment == 4 ~ \"Self\")) gotv <- gotv |>\n  mutate(\n    age = floor(2006 - yob),\n    treatment = case_when(\n      treatment == 0 ~ \"Control\",\n      treatment == 1 ~ \"Hawthorne\",\n      treatment == 2 ~ \"Civic Duty\",\n      treatment == 3 ~ \"Neighbors\",\n      treatment == 4 ~ \"Self\")\n    ) \nglimpse(gotv)## Rows: 344,084\n## Columns: 17\n## $ sex           <dbl+lbl> 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,…\n## $ yob           <dbl> 1941, 1947, 1951, 1950, 1982, 1981, …\n## $ g2000         <dbl+lbl> 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,…\n## $ g2002         <dbl+lbl> 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,…\n## $ g2004         <dbl+lbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n## $ p2000         <dbl+lbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ p2002         <dbl+lbl> 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,…\n## $ p2004         <dbl+lbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,…\n## $ treatment     <chr> \"Civic Duty\", \"Civic Duty\", \"Hawthor…\n## $ cluster       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ voted         <dbl+lbl> 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,…\n## $ hh_id         <dbl> 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 5, 6, …\n## $ hh_size       <dbl> 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 1, 2, …\n## $ numberofnames <dbl> 21, 21, 21, 21, 21, 21, 21, 21, 21, …\n## $ p2004_mean    <dbl> 0.09523810, 0.09523810, 0.04761905, …\n## $ g2004_mean    <dbl> 0.8571429, 0.8571429, 0.8571429, 0.8…\n## $ age           <dbl> 65, 59, 55, 56, 24, 25, 47, 50, 38, …"},{"path":"discussion-3.-analyzing-an-experiment-in-r-solutions.html","id":"balance-table-1","chapter":"Discussion 3. Analyzing an Experiment in R SOLUTIONS","heading":"13.7.3 Balance table","text":"Next, confirm control treatment groups look pretty much across set covariates, .e. two groups balanced covariates. Specifically means calculate mean value set covariates across treatment/control arms, expect pretty much equal randomization worked. related idea exchangeability.solution uses functions group_by, summarise, across.may done something different. output (similar), fine!alternative solution explicitly use group_by:","code":"\ncovariates <- c(\"sex\", \"age\", \"g2000\", \"g2002\", \"p2000\", \"p2002\", \"p2004\", \"hh_size\")\n\ngotv_balance <- gotv |>\n  group_by(treatment) |>\n  summarise(across(.cols = covariates, .fns = mean))\n\nprint(gotv_balance)## # A tibble: 5 × 9\n##   treatment    sex   age g2000 g2002 p2000 p2002 p2004\n##   <chr>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n## 1 Civic Duty 0.500  49.7 0.842 0.811 0.254 0.389 0.399\n## 2 Control    0.499  49.8 0.843 0.811 0.252 0.389 0.400\n## 3 Hawthorne  0.499  49.7 0.844 0.813 0.250 0.394 0.403\n## 4 Neighbors  0.500  49.9 0.842 0.811 0.251 0.387 0.407\n## 5 Self       0.500  49.8 0.840 0.811 0.251 0.392 0.402\n## # ℹ 1 more variable: hh_size <dbl>covariates <- c(\"sex\", \"age\", \"g2000\", \"g2002\", \"p2000\", \"p2002\", \"p2004\", \"hh_size\")\n\ngotv_results <- gotv |>\n  summarise(\n    across(.cols = all_of(covariates), .fns = mean),\n    .by = treatment\n    )\nprint(gotv_results)"},{"path":"discussion-3.-analyzing-an-experiment-in-r-solutions.html","id":"results-1","chapter":"Discussion 3. Analyzing an Experiment in R SOLUTIONS","heading":"13.7.4 Results","text":"Finally, treatment group, calculate percentage individuals got voted, well total number individuals group! solutions use function n counts number observations current group .Alternatively, write without using group_by explicitly:","code":"\ngotv_results <- gotv |>\n  group_by(treatment) |>\n  summarise(Percentage_Voting = mean(voted), num_of_individuals = n())\n\nprint(gotv_results)## # A tibble: 5 × 3\n##   treatment  Percentage_Voting num_of_individuals\n##   <chr>                  <dbl>              <int>\n## 1 Civic Duty             0.315              38218\n## 2 Control                0.297             191243\n## 3 Hawthorne              0.322              38204\n## 4 Neighbors              0.378              38201\n## 5 Self                   0.345              38218gotv |>\n  summarise(Percentage_Voting = mean(voted), num_of_individuals = n(), .by = treatment)"},{"path":"discussion-7.-causal-effects-with-matching.html","id":"discussion-7.-causal-effects-with-matching","chapter":"Discussion 7. Causal Effects with Matching","heading":"Discussion 7. Causal Effects with Matching","text":"Slides\nDownload today’s .Rmd document .packages may need install first:optmatch: install.packages(\"optmatch\")sandwich: install.packages(\"sandwich\")MatchIt: install.packages(\"MatchIt\")marginaleffects: install.packages(\"marginaleffects\")","code":""},{"path":"discussion-7.-causal-effects-with-matching.html","id":"r-markdown","chapter":"Discussion 7. Causal Effects with Matching","heading":"13.8 R Markdown","text":"Learn matching “MatchIt” packageFirst, ’ll use data set last week compare greedy vs optimal matching. ’ll use NLSY data since larger.First compare optimal vs greedy. Optimal matching usually better greedy matching, long data isn’t bigOn full data, using optimal possible, can take bit time. larger data sets, might possible","code":"\nd <- readRDS(\"assets/discussions/d.RDS\")\n\n# matchit function implements matching\n# Formula: Treatment ~ variables to match on\n# method: nearest is a greedy 1:1 matching without replacement\n# distance: euclidean (other possible options are scaled_euclidean, mahalanobis, robust_mahalanobis)\n# read more on distances here: https://rdrr.io/cran/MatchIt/man/distance.html#mat\nm.out0 <- matchit(a == \"college\" ~ log_parent_income + log_parent_wealth\n                              + test_percentile,\n                              method = \"nearest\", distance = \"euclidean\",\n                              data = d)\n## Optimal vs greedy with NYLSR data\n# With n = 1000; .01 sec vs .8 sec\n# With n = 2000; .05 sec vs 8 sec\n# With n = 4000; .1 vs 25\n\nind <- sample(nrow(d), size = 1000)\n\n# Greedy is using nearest\nsystem.time(m.out0 <- matchit(a == \"college\" ~ log_parent_income + log_parent_wealth\n                              + test_percentile,\n                              method = \"nearest\", distance = \"euclidean\",\n                              data = d[ind, ]))##    user  system elapsed \n##   0.016   0.000   0.016\n# method: optimal is optimal matching\nsystem.time(m.out0 <- matchit(a == \"college\" ~ log_parent_income + log_parent_wealth\n                              + test_percentile,\n                              method = \"optimal\", distance = \"euclidean\",\n                              data = d[ind, ]))##    user  system elapsed \n##   1.290   0.077   1.524\n# With full data set greedy matching takes ~ 0.5-1.5 seconds\nsystem.time(m.out0 <- matchit(a == \"college\" ~ log_parent_income + log_parent_wealth\n                              + test_percentile,\n                              method = \"nearest\", distance = \"euclidean\",\n                              data = d))##    user  system elapsed \n##   0.605   0.077   0.684\n# Meanwhile, optimal matching takes 60-130 seconds\nsystem.time(m.out0 <- matchit(a == \"college\" ~ log_parent_income + log_parent_wealth\n                              + test_percentile,\n                              method = \"optimal\", distance = \"euclidean\",\n                              data = d))##    user  system elapsed \n## 117.511   5.250 124.215"},{"path":"discussion-7.-causal-effects-with-matching.html","id":"matching-with-job-training-data-from-evaluating-the-econometric-evaluations-of-training-programs-with-experimental-data-lalonde-1986","chapter":"Discussion 7. Causal Effects with Matching","heading":"13.9 Matching with job training data from “Evaluating the econometric evaluations of training programs with experimental data” (LaLonde 1986)","text":"remainder lab, ’ll use portion data job training program. particular, treatment whether someone participated job training program. outcome interest salary 1978 (re78).expect income 1974 highly correlated income 1975. also much higher variability age.Now let’s try run matching procedure using function.","code":"\n# Load the data\ndata(\"lalonde\")\n\n# See what's in the data\n?lalonde # this opens up the \"Help\" tab with the documentation! \nhead(lalonde)##      treat age educ   race married nodegree re74 re75\n## NSW1     1  37   11  black       1        1    0    0\n## NSW2     1  22    9 hispan       0        1    0    0\n## NSW3     1  30   12  black       0        0    0    0\n## NSW4     1  27   11  black       0        1    0    0\n## NSW5     1  33    8  black       0        1    0    0\n## NSW6     1  22    9  black       0        1    0    0\n##            re78\n## NSW1  9930.0460\n## NSW2  3595.8940\n## NSW3 24909.4500\n## NSW4  7506.1460\n## NSW5   289.7899\n## NSW6  4056.4940\n## Suppose there are 3 individuals\ndat <- matrix(c(50, 5000, 5500,\n                20, 5100, 5900,\n                40, 5200, 6200), ncol = 3, byrow = T)\ncolnames(dat) <- c(\"age\", \"re74\", \"re75\")\n\n# Is individual 2 or 3 more similar to individual 1? \n# To answer this, we should compute the distances between individuals 1 and 2, and 1 and 3. \n\n# One way is to compute the Mahalanobis distance by first computing the covariance matrix of the confounding variables\n# In this case, the confounders are age, re74, and re75\ndataCov <- lalonde %>%\n  select(age, re74, re75) %>%\n  cov\n\n# Then we compute the Mahalanobis distance with the function mahalanobis_dist\nmahalanobis_dist( ~ age + re74 + re75, data = dat, var = dataCov)##          1        2        3\n## 1 0.000000 3.225953 1.098595\n## 2 3.225953 0.000000 2.152528\n## 3 1.098595 2.152528 0.000000\n# We can also compute the Euclidean distance\ndist(dat, method = \"euclidean\")##          1        2\n## 2 413.4005         \n## 3 728.0797 316.8596\n# For now, let's start with Euclidean distance, even if may not be great\n\n# method: nearest (i.e. greedy 1:1)\n# distance: euclidean\n# data: lalonde (the data set we're working with)\n# replace: True (T) or False (F) - whether to sample with or without replacement. \n    # Note, if allowing for replacement, greedy and optimal are the same\n    # So for the function, you only need to specify if using method = \"nearest\"\n# ratio: how many control matches for each treated unit\n# caliper: by default, the caliper width in standard units (i.e., Z-scores)\nm.out0 <- matchit(treat ~ re74 + re75 + age + race,\n                  method = \"nearest\", distance = \"euclidean\",\n                  data = lalonde, replace = F, \n                  ratio = 1, caliper = c(re74  = .2, re75 = .2))"},{"path":"discussion-7.-causal-effects-with-matching.html","id":"assessing-the-matching","chapter":"Discussion 7. Causal Effects with Matching","heading":"13.10 Assessing the matching","text":"can check well balancing doneWe can also visually asses matchesAs first step, simply compare means outcomes groups. Notice first time ’ve looked outcomes!","code":"\n?summary.matchit # Look in the Help tab (on the bottom right) for documentation on summary.matchit\n\n\n# interactions: check interaction terms too? (T or F)\n# un: show statistics for unmatched data as well (T or F)\nsummary(m.out0, interactions = F, un = F)## \n## Call:\n## matchit(formula = treat ~ re74 + re75 + age + race, data = lalonde, \n##     method = \"nearest\", distance = \"euclidean\", replace = F, \n##     caliper = c(re74 = 0.2, re75 = 0.2), ratio = 1)\n## \n## Summary of Balance for Matched Data:\n##            Means Treated Means Control Std. Mean Diff.\n## re74           1643.2931     1666.9106         -0.0048\n## re75           1021.5989     1086.1734         -0.0201\n## age              25.6971       26.1543         -0.0639\n## raceblack         0.8400        0.2800          1.5403\n## racehispan        0.0571        0.1714         -0.4833\n## racewhite         0.1029        0.5486         -1.5040\n##            Var. Ratio eCDF Mean eCDF Max Std. Pair Dist.\n## re74           1.0122    0.0108   0.1543          0.0293\n## re75           1.0026    0.0166   0.1543          0.0422\n## age            0.4213    0.0894   0.2000          0.9967\n## raceblack           .    0.5600   0.5600          1.7289\n## racehispan          .    0.1143   0.1143          0.7249\n## racewhite           .    0.4457   0.4457          1.6968\n## \n## Sample Sizes:\n##           Control Treated\n## All           429     185\n## Matched       175     175\n## Unmatched     254      10\n## Discarded       0       0\n# Std. Mean Diff (SMD): difference of means, standardized by sd of treatment group\n# Var. Ratio: ratio of variances in treatment and control group. Compares spread of data\n# Rubin (2001) presents rule of thumb that SMD should be less than .25 and variance ratio should be between .5 and 2\n# Max eCDF: Kolmogorov-Smirnov statistic. Max difference across entire CDF\n## Produces QQ plots of all variables in which.xs\nplot(m.out0, type = \"qq\", which.xs = ~age + re74, interactive = F)\n## Plots the density of all variables in which.xs\nplot(m.out0, type = \"density\", which.xs = ~age + re74 + race, interactive = F)\n## Plots the empirical CDF of all variables in which.xs\nplot(m.out0, type = \"ecdf\", which.xs = ~age + re74, interactive = F)\n# Produces data frame same as input, but has two additional columns\n# weights: the weight of the row in the paired data set. Can be greater than 1\n#         if the data set was matched more than once\n# subclass: the index of the \"pair\"\n#\nm.out0.data <- match.data(m.out0, drop.unmatched = T)\nhead(m.out0.data)##      treat age educ   race married nodegree re74 re75\n## NSW1     1  37   11  black       1        1    0    0\n## NSW2     1  22    9 hispan       0        1    0    0\n## NSW3     1  30   12  black       0        0    0    0\n## NSW4     1  27   11  black       0        1    0    0\n## NSW5     1  33    8  black       0        1    0    0\n## NSW6     1  22    9  black       0        1    0    0\n##            re78 weights subclass\n## NSW1  9930.0460       1        1\n## NSW2  3595.8940       1       88\n## NSW3 24909.4500       1       99\n## NSW4  7506.1460       1      110\n## NSW5   289.7899       1      121\n## NSW6  4056.4940       1      132\nnames(m.out0.data)##  [1] \"treat\"    \"age\"      \"educ\"     \"race\"     \"married\" \n##  [6] \"nodegree\" \"re74\"     \"re75\"     \"re78\"     \"weights\" \n## [11] \"subclass\"\n# Also produces matched data set, though will duplicate rows if matching with replacement\n# and a control is matched more than once\nm.out0.data <- get_matches(m.out0)\n# Take the mean of both groups\n# this will only work if all weights are 1\naggregate(re78~ treat, FUN = mean, data = m.out0.data)##   treat     re78\n## 1     0 5422.184\n## 2     1 6193.594\n# Fitting a linear model on the treatments will work\n# even if all weights are not 1. We just need to feed them in\nfit1 <- lm(re78~ treat, data = m.out0.data, weights = weights)\n\n# vcov: tells R to use robust standard errors\navg_comparisons(fit1, variables = \"treat\",\n                vcov = \"HC3\",\n                newdata = subset(m.out0.data, treat == 1),\n                wts = \"weights\")## Warning: The `treat` variable is treated as a categorical\n##   (factor) variable, but the original data is of class\n##   integer. It is safer and faster to convert such\n##   variables to factor before fitting the model and\n##   calling `slopes` functions.\n##   \n##   This warning appears once per session.## \n##   Term Contrast Estimate Std. Error    z Pr(>|z|)   S 2.5 %\n##  treat    1 - 0      771        753 1.02    0.306 1.7  -705\n##  97.5 %\n##    2248\n## \n## Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n## Type:  response"},{"path":"discussion-7.-causal-effects-with-matching.html","id":"fit-your-own-model","chapter":"Discussion 7. Causal Effects with Matching","heading":"13.11 Fit your own model","text":"Now try . Note, need something similar homework dataset.Think appropriate DAG might choose variables want match \nAsk : know choose variables match ?\nAsk : know choose variables match ?Choose matching procedure\nAsk : know explain matching procedure bias-variance trade ?\nAsk : know explain matching procedure bias-variance trade ?Evaluate balance match. doesn’t look good, try another matching procedure\nAsk : know balanced matching looks like?\nAsk : know balanced matching looks like?Estimate causal effect\nAsk : know just estimated?\nAsk : know just estimated?","code":""},{"path":"due-dates.html","id":"due-dates","chapter":"Due dates","heading":"Due dates","text":"Th 31 Aug, 5pm. Submit HW 1.Th 7 Sep, 5pm. Peer reviews HW 1.Th 14 Sep, 5pm. Submit HW 2.Th 21 Sep, 5pm. Peer reviews HW 2.Th 28 Sep, 5pm. Submit HW 3.Th 5 Oct, 5pm. Peer reviews HW 3.Th 19 Oct, 5pm. Submit HW 4.Th 26 Oct, 5pm. Peer reviews HW 4.Th 2 Nov, 5pm. Submit HW 5.Th 9 Nov, 5pm. Peer reviews HW 5.Th 16 Nov, 5pm. Submit HW 6.note: peer reviews homeworkT 21 Nov, 5pm. Submit project writeup.W 29 Nov. Present project lab.","code":""},{"path":"final-project.html","id":"final-project","chapter":"Final Project","heading":"Final Project","text":"final project opportunity engage published research paper asks causal question. choose one paper set prepared. paper, carry two tasks.","code":""},{"path":"final-project.html","id":"summarize-what-the-authors-have-done","chapter":"Final Project","heading":"1. Summarize what the authors have done","text":"Choose one causal estimand paper. estimand,Define estimand using potential outcomesPresent identification assumptions link quantity observable dataDiscuss estimator authors use estimate target quantityIn many papers, three steps stated English may involve ambiguity. may certain quantity authors wanted estimate, exactly assumed. settings, task choose one interpretation authors done make interpretation precise.","code":""},{"path":"final-project.html","id":"propose-a-new-quantity-to-estimate","chapter":"Final Project","heading":"2. Propose a new quantity to estimate","text":"second part, propose new causal estimand. collect new data conduct new analysis estimate new quantity, quantity ? part assignment, can write though unlimited resources collect amount kind data want.Define new causal estimandPresent identification assumptions link quantity observable dataDiscuss estimator use estimate target quantityThere one restriction: part 2, proposed analysis involve randomized treatment. experiments terrific ways conducting research, identification estimation assumptions randomized experiments can trivial. order practice skills learned class, want focus non-randomized setting.","code":""},{"path":"final-project.html","id":"format-of-the-final-project","chapter":"Final Project","heading":"Format of the final project","text":"","code":""},{"path":"final-project.html","id":"working-in-groups","chapter":"Final Project","heading":"Working in groups","text":"anticipate students carry final project groups 4–5 students discussion section. Near middle semester, circulate form tell us people ’d like work , ’d like us randomize group can meet new people. prefer work alone, just come talk us, can discuss work.","code":""},{"path":"final-project.html","id":"writeup","chapter":"Final Project","heading":"Writeup","text":"Writeup due Nov 21 5pmYour group submit writeup 1,500 2,000 words, typeset using RMarkdown.","code":""},{"path":"final-project.html","id":"presentation","chapter":"Final Project","heading":"Presentation","text":"Presentations Nov 29 discussionEach group make 10-minute presentation, using slides. presentation involve parts (1) (2).","code":""},{"path":"final-project.html","id":"grading","chapter":"Final Project","heading":"Grading","text":"post rubrics Canvas assign final project groups.","code":""},{"path":"final-project.html","id":"published-papers-for-the-project","chapter":"Final Project","heading":"Published papers for the project","text":"group study one following papers:Stuart, E. ., & Green, K. M. (2008). Using full matching estimate causal effects nonexperimental studies: Examining relationship adolescent marijuana use adult outcomes. Developmental Psychology, 44(2), 395.\npaper example matching\npaper example matchingHalloran, M. E., & Hudgens, M. G. (2018). Estimating population effects vaccination using large, routinely collected data. Statistics Medicine, 37(2), 294-301.\npaper example addressing interference\npaper example addressing interferenceEggers, . C., & Hainmueller, J. (2009). MPs sale? Returns office postwar British politics. American Political Science Review, 103(4), 513-533.\npaper example regression discontinuity\npaper example regression discontinuityAcharya, ., Blackwell, M., & Sen, M. (2016). political legacy American slavery. Journal Politics, 78(3), 621-641.\npaper example instrumental variables\npaper example instrumental variables","code":""},{"path":"problem-set-1.-definitions.html","id":"problem-set-1.-definitions","chapter":"Problem Set 1. Definitions","heading":"Problem Set 1. Definitions","text":"Relevant material covered Aug 24. Problem set due Aug 31.Welcome problem set! homework practice conceptual notation ideas descriptive causal inference.complete problem set, Download .Rmd complete homework. Omit name can anonymous peer feedback. Compile PDF submit PDF Canvas.","code":""},{"path":"problem-set-1.-definitions.html","id":"practice-with-potential-outcomes","chapter":"Problem Set 1. Definitions","heading":"1. Practice with potential outcomes","text":"Jose says coming Cornell caused discover statistics, became major! says gone NYU, stuck biology.","code":""},{"path":"problem-set-1.-definitions.html","id":"points","chapter":"Problem Set 1. Definitions","heading":"1.1 (7 points)","text":"Jose’s claim, treatment?Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-1","chapter":"Problem Set 1. Definitions","heading":"1.2 (7 points)","text":"Using mathematical notation discussed class, define two potential outcomes Jose referringAnswer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-2","chapter":"Problem Set 1. Definitions","heading":"1.3 (7 points)","text":"sentence two, say Fundamental Problem Causal Inference applies Jose’s claim.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-3","chapter":"Problem Set 1. Definitions","heading":"1.4 (7 points)","text":"Using conditional expectations probabilities, write following math: probability majoring statistics higher among students attend Cornell among students attend NYU.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-4","chapter":"Problem Set 1. Definitions","heading":"1.5 (7 points)","text":"Give one reason average causal effect attending Cornell versus NYU (quantity 1.2, averaged students) might different average descriptive difference (1.4) rates majoring statistics.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"a-sailing-class","chapter":"Problem Set 1. Definitions","heading":"2. A sailing class","text":"looking sailing class Cornell Wellness! claim , tell us whether claim causal descriptive.","code":""},{"path":"problem-set-1.-definitions.html","id":"points-5","chapter":"Problem Set 1. Definitions","heading":"2.1 (5 points)","text":"Last year, survey students take class. proportion reporting felt prepared sail Cayuga Lake higher among took class.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-6","chapter":"Problem Set 1. Definitions","heading":"2.2 (5 points)","text":"Last year, survey students class. proportion reporting felt prepared sail Cayuga Lake higher survey taken class.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"points-7","chapter":"Problem Set 1. Definitions","heading":"2.3 (5 points)","text":"average, students class emerged prepared sail without class.Answer. answer ","code":""},{"path":"problem-set-1.-definitions.html","id":"session-info","chapter":"Problem Set 1. Definitions","heading":"Session info","text":"chunk record information R session, useful debugging issues homework assignments contain code.","code":"\nsessionInfo()## R version 4.3.1 (2023-06-16)\n## Platform: x86_64-apple-darwin20 (64-bit)\n## Running under: macOS Ventura 13.4.1\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib \n## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## time zone: America/New_York\n## tzcode source: internal\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets \n## [6] methods   base     \n## \n## loaded via a namespace (and not attached):\n##  [1] digest_0.6.31   R6_2.5.1        bookdown_0.34  \n##  [4] fastmap_1.1.1   xfun_0.39       cachem_1.0.8   \n##  [7] knitr_1.43      memoise_2.0.1   htmltools_0.5.5\n## [10] rmarkdown_2.22  xml2_1.3.4      cli_3.6.1      \n## [13] downlit_0.4.2   sass_0.4.6      withr_2.5.1    \n## [16] jquerylib_0.1.4 compiler_4.3.1  rstudioapi_0.14\n## [19] tools_4.3.1     evaluate_0.21   bslib_0.5.0    \n## [22] yaml_2.3.7      fs_1.6.2        jsonlite_1.8.5 \n## [25] rlang_1.1.1"},{"path":"problem-set-2.-experiments.html","id":"problem-set-2.-experiments","chapter":"Problem Set 2. Experiments","heading":"Problem Set 2. Experiments","text":"Relevant material covered Sep 7. Problem set due Sep 14.complete problem set, Download .Rmd complete homework. Omit name can anonymous peer feedback. Compile PDF submit PDF Canvas.problem set based :Bertrand, M & Mullainathan, S. 2004. “Emily Greg Employable Lakisha Jamal? Field Experiment Labor Market Discrimination.” American Economic Review 94(4):991–1013.’s heads-hard problem setfor , reading social science paper hardfor , mathematical statistics hardfor , R coding hardFor almost one three easy.want support succeed! Text format help .","code":""},{"path":"problem-set-2.-experiments.html","id":"conceptual-questions-about-the-study-design","chapter":"Problem Set 2. Experiments","heading":"1. Conceptual questions about the study design","text":"Read first 10 pages paper (end section 2). paper,unit analysis resume submitted job openingthe treatment name top resumethe outcome whether employer called emailed back interview","code":""},{"path":"problem-set-2.-experiments.html","id":"points-fundamental-problem","chapter":"Problem Set 2. Experiments","heading":"1.1. (5 points) Fundamental Problem","text":"One submitted resume name “Emily Baker.” yielded callback. resume name “Lakisha Washington.” Explain Fundamental Problem Causal Inference applies case (1–2 sentences).","code":""},{"path":"problem-set-2.-experiments.html","id":"points-exchangeability","chapter":"Problem Set 2. Experiments","heading":"1.2. (5 points) Exchangeability","text":"sentence, state exchangeability means study. concreteness, question may suppose names study “Emily Baker” “Lakisha Washington.” sure explicitly state treatment potential outcomes.","code":""},{"path":"problem-set-2.-experiments.html","id":"points-something-you-liked","chapter":"Problem Set 2. Experiments","heading":"1.3. (10 points) Something you liked","text":"State something concrete appreciate study design, randomization.","code":""},{"path":"problem-set-2.-experiments.html","id":"analyzing-the-experimental-data","chapter":"Problem Set 2. Experiments","heading":"2. Analyzing the experimental data","text":"Load packages code use.Download study’s data OpenICPSR: https://www.openicpsr.org/openicpsr/project/116023/version/V1/view. require creating account agreeing terms using data ethically. Put data folder computer .Rmd located. Read data R using read_dta.error, might need set working directory first. tells R look data files. top RStudio, click Session -> Set Working Directory -> Source File Location.now see d Global Environment top right RStudio.use four variables:2.1–2.4, think race treatment. 2.5–2.6, think firstname treatment.Restrict variables using select().new R, just happened:created new object d_selectedused assignment operator <- put something objectwe started data object dwe used pipe operator %>% hand d new actionthe action select() selected variables interestWe often analyze data starting data object handing series actions connected pipe %>%","code":"\nlibrary(tidyverse)\nlibrary(haven)\nd <- read_dta(\"lakisha_aer.dta\")\nd_selected <- d %>%\n  select(call, firstname, race, sex)"},{"path":"problem-set-2.-experiments.html","id":"points-point-estimates-of-expected-potential-outcomes","chapter":"Problem Set 2. Experiments","heading":"2.1. (5 points) Point estimates of expected potential outcomes","text":"top Table 1 reports callback rates: 9.65% white names 6.45% Black names. Reproduce numbers. , take code add group_by() action d_selected summarize.’s reference introduces group_by summarize.","code":"\nd_summarized <- d_selected %>%\n  summarize(callback_rate = mean(call),\n            number_cases = n()) %>%\n  print()## # A tibble: 1 × 2\n##   callback_rate number_cases\n##           <dbl>        <int>\n## 1        0.0805         4870"},{"path":"problem-set-2.-experiments.html","id":"points-inference-for-expected-potential-outcomes","chapter":"Problem Set 2. Experiments","heading":"2.2. (5 points) Inference for expected potential outcomes","text":"Use mutate() (see reference page) create new columns containing standard error estimate well lower upper limits 95% confidence intervals.make easier, quick math review R functions can use.Standard error math. Let \\(Y^\\) Bernoulli random variable, taking value 1 random resume name \\(\\) yields callback 0 otherwise. Let \\(\\pi^= P(Y^=1)\\) probability callback. statistics, know variance \\(V(Y^) = \\pi^(1-\\pi^)\\). estimated average: \\(\\hat\\pi^= \\frac{1}{n_a}\\sum_{:A_i=} Y_i^\\). many times many hypothetical samples, always get estimate. fact, estimate sampling variance \\(V(\\hat\\pi^) = \\frac{\\pi^(1-\\pi^)}{n_a}\\). know \\(\\hat\\pi^\\) mean \\(n_a\\) independent identically distributed random variables \\(Y^\\). standard error square root sampling variance: \\(SE(\\hat\\pi^) = \\sqrt\\frac{\\pi^(1-\\pi^)}{n_a}\\). can estimate standard error plugging estimate \\(\\hat\\pi^\\) true unknown \\(\\pi^\\) wherever appears.Standard error code. translated standard error formula code . function accepts estimated probability p sample size n returns estimated standard error. can use se_binary() function code within mutate() just like mean() used within summarize() start problem set.Sampling distribution math. \\(\\hat\\pi^\\) sample mean, know something sampling distribution: limit sample size grows infinity, across hypothetical repeated samples distribution \\(\\hat\\pi^\\) estimates becomes Normal. Central Limit Theorem! Across repeated samples, middle 95% estimates fall within known range: \\(\\pi^\\pm \\Phi^{-1}(.975) \\times SE(\\hat\\pi^)\\), \\(\\Phi^{-1}()\\) inverse cumulative distribution function standard Normal distribution. might previously learned \\(\\Phi^{-1}(.975) \\approx 1.96\\), might familiar number 1.96.Sampling distribution graph.Confidence interval math. get 95% confidence interval plugging estimates \\(\\hat\\pi^\\) \\(\\widehat{SE}(\\hat\\pi^)\\) limits . interval centered estimate \\(\\hat\\pi^\\) nice property: repeatedly made confidence interval procedure using hypothetical samples population, interval contain unknown true parameter \\(\\pi^\\) 95% time.Confidence interval code. translated confidence interval formula code . functions accept estimate standard error return lower upper bounds (respectively) 95% confidence interval assumes Normal sampling distribution. can use functions code within mutate() just like mean() used within summarize() start problem set.","code":"\nse_binary <- function(p, n) {\n  se <- sqrt( p * (1 - p) / n )\n  return(se)\n}\nci_lower <- function(estimate, standard_error) {\n  estimate - qnorm(.975) * standard_error\n}\nci_upper <- function(estimate, standard_error) {\n  estimate + qnorm(.975) * standard_error\n}"},{"path":"problem-set-2.-experiments.html","id":"points-interpret-your-confidence-interval","chapter":"Problem Set 2. Experiments","heading":"2.3. (5 points) Interpret your confidence interval","text":"words, interpret confidence intervals. sure discuss property hypothetical repeated samples, sure frame answer using numbers variables actual experiment analyzing.","code":""},{"path":"problem-set-2.-experiments.html","id":"points-visualize-expected-potential-outcomes","chapter":"Problem Set 2. Experiments","heading":"2.4. (5 points) Visualize expected potential outcomes","text":"Using ggplot(), visualize estimated callback rate race. Use geom_point() point estimates geom_errorbar() confidence intervals, race x axis estimates y axis. Label axes using full words.never used ggplot, see Ch 3 R Data Science Hadley Wickham.","code":""},{"path":"problem-set-2.-experiments.html","id":"points-estimate-and-visualize-by-firstname","chapter":"Problem Set 2. Experiments","heading":"2.5. (5 points) Estimate and visualize by firstname","text":"distinct first names yield distinct effects? Repeat 2.2–2.4, now create estimates grouped race, sex, firstname. Visualize point estimates confidence intervals.One way visualize placing first names \\(x\\)-axis using facet_wrap() layer facet race sex.strategy visualize fine, long shows estimates firstname indicates race sex signaled firstname","code":"\nyour_ggplot +\n  facet_wrap(~ race + sex,\n             scales = \"free_x\", \n             nrow = 1)"},{"path":"problem-set-2.-experiments.html","id":"points-interpret","chapter":"Problem Set 2. Experiments","heading":"2.6. (5 points) Interpret","text":"Within race sex, first names effect. Suppose true differences (due sampling variability). tell importance researcher decisions names use treatments?","code":""},{"path":"problem-set-3.-dags..html","id":"problem-set-3.-dags.","chapter":"Problem Set 3. DAGs.","heading":"Problem Set 3. DAGs.","text":"Relevant material covered Sep 21. Problem set due Sep 28.complete problem set, copy code .Rmd complete homework. Omit name can anonymous peer feedback. Compile PDF submit PDF Canvas.Note: problem set , alternatively may complete homework hand. welcome draw DAGs hand instead producing code. , scan take picture document.","code":""},{"path":"problem-set-3.-dags..html","id":"true-or-false","chapter":"Problem Set 3. DAGs.","heading":"1. True or False","text":"1.1–1.5, answer True False: \\(X\\) sufficient adjustment set identify causal effect \\(\\) \\(Y\\). Explain one sentence. False, state backdoor path unblocked conditional \\(X\\). path linear series nodes connected arrows; see examples 1.6 1.7.","code":""},{"path":"problem-set-3.-dags..html","id":"points-8","chapter":"Problem Set 3. DAGs.","heading":"1.6 (3 points)","text":"True False? Conditioning \\(X\\) blocks path: \\(\\leftarrow B \\leftarrow X \\rightarrow C \\rightarrow Y\\)","code":""},{"path":"problem-set-3.-dags..html","id":"points-9","chapter":"Problem Set 3. DAGs.","heading":"1.7 (3 points)","text":"True False? Conditioning \\(X\\) blocks path: \\(\\leftarrow B \\rightarrow X \\leftarrow C \\rightarrow Y\\)","code":""},{"path":"problem-set-3.-dags..html","id":"draw-a-dag-10-points","chapter":"Problem Set 3. DAGs.","heading":"2. Draw a DAG (10 points)","text":"researcher comes proposal: identify causal effect \\(\\) \\(Y\\) adjusting variable \\(X\\) predicts \\(\\) also predicts \\(Y\\). propose machine learning can thus solve causal identification us.researcher wrong. Show . Draw DAG whichthe effect \\(\\) \\(Y\\) unconfoundeda variable \\(X\\) statistically associated \\(\\)variable \\(X\\) statistically associated \\(Y\\)one need adjust \\(X\\) identify causal effect","code":""},{"path":"problem-set-3.-dags..html","id":"using-dags-in-a-new-context","chapter":"Problem Set 3. DAGs.","heading":"3. Using DAGs in a new context","text":"DAGs just useful causal inference: can useful whenever need know whether one variable statistically independent another. true, example, drawing inference population sample.researcher uses opt-online web survey draw inference support President Biden. ask respondents: ``approve President Biden’s performance office?’’ answer choices Yes/. researcher also gathers data two demographic characteristics: whether respondent completed college current employment. write:sample representative. Suppose every person population, \\(S\\) denotes whether included sample. \\(S\\) related approval President Biden (\\(Y\\)).However, believe sample representative look set people take value along college completion employment, finished college currently employed. variables \\(X_1,X_2\\), believe independence statement: \\(S\\) independent \\(Y\\) given \\(X_1,X_2\\). therefore get population estimates procedure several steps: use sample estimate mean outcome \\(E(Y\\mid \\vec{X} = \\vec{x})\\) stratum, use Census data estimate size stratum \\(P(\\vec{X} = \\vec{x})\\) population, estimate \\(E(Y) = \\sum_{\\vec{x}}E(Y\\mid \\vec{X} = \\vec{x})P(\\vec{X} = \\vec{x})\\).researcher’s reasoning common strategy known post-stratification. question formalizing set conditions researcher right wrong.begin, want emphasize one aspect researcher’s assumption different exchangeability assumption causal inference.causal claims, assume conditional exchangeability: \\(\\) independent \\(Y^\\) given \\(\\vec{X}\\)\ninvolves potential outcome \\(Y^\\)\nholds unblocked paths \\(\\) \\(Y\\) causal paths\ninvolves potential outcome \\(Y^\\)holds unblocked paths \\(\\) \\(Y\\) causal pathsfor sample--population inference, assume conditionally independent sampling \\(S\\) independent \\(Y\\) given \\(\\vec{X}\\)\ninvolves factual outcome \\(Y\\); intervention \nholds unblocked paths \\(S\\) \\(Y\\)\ninvolves factual outcome \\(Y\\); intervention hereholds unblocked paths \\(S\\) \\(Y\\)Although assumption different, principles DAGs still relevant.","code":""},{"path":"problem-set-3.-dags..html","id":"points-10","chapter":"Problem Set 3. DAGs.","heading":"3.1. (5 points)","text":"Draw DAG researcher’s claim valid. Use \\(S,Y,X_1,X_2\\).","code":""},{"path":"problem-set-3.-dags..html","id":"points-11","chapter":"Problem Set 3. DAGs.","heading":"3.2. (2 points)","text":"sentence two, explain DAG 3.1 researcher. Tell us words meant edge DAG.","code":""},{"path":"problem-set-3.-dags..html","id":"points-12","chapter":"Problem Set 3. DAGs.","heading":"3.3. (5 points)","text":"Draw DAG showing counterexample researcher’s claim invalid.","code":""},{"path":"problem-set-3.-dags..html","id":"points-13","chapter":"Problem Set 3. DAGs.","heading":"3.4 (2 points)","text":"sentence two, explain DAG 3.3 researcher. Tell us particularly path creates statistical dependence \\(S\\) \\(Y\\).","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"problem-set-4.-statistical-modeling","chapter":"Problem Set 4. Statistical modeling","heading":"Problem Set 4. Statistical modeling","text":"Relevant material covered Oct 5. Problem set due Oct 19.complete problem set, Download .Rmd complete homework. Omit name can anonymous peer feedback. Compile PDF submit PDF Canvas.learning goals completing problem set areexplain role statistical modeling\nrespect causal claims\nrespect data sparsity\nrespect causal claimswith respect data sparsityestimate average treatment effects \nexact matching (setting confounders)\nlearning outcome model\nlearning treatment model\nmatching method choosing\nexact matching (setting confounders)learning outcome modellearning treatment modela matching method choosingThe reason practicing many statistical modeling estimators can see ideas class apply estimators—future estimators encounter part class!problem set uses data following paper:Dehejia, R. H. Wahba, S. 1999. Causal Effects Nonexperimental Studies: Reevaluating Evaluation Training Programs. Journal American Statistical Association 94(448):1053–1062.paper compares methods observational causal inference recover average causal effect already known randomized experiment. need read paper; just use study’s data illustration.following lines load data R.learn data, type ?lalonde R console.","code":"\nlibrary(tidyverse)\nlibrary(MatchIt)\ndata(\"lalonde\")"},{"path":"problem-set-4.-statistical-modeling.html","id":"conceptual-questions","chapter":"Problem Set 4. Statistical modeling","heading":"1. Conceptual questions","text":"","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-statistical-modeling-and-causal-claims","chapter":"Problem Set 4. Statistical modeling","heading":"1.1. (5 points) Statistical modeling and causal claims","text":"Imagine someone taken class tells don’t need DAGs causal assumptions know really good matching method. 3 sentences, explain causal assumptions necessary matching yield causal conclusions.","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"nonparametric-estimation","chapter":"Problem Set 4. Statistical modeling","heading":"2. Nonparametric estimation","text":"goal estimate effect job training treat future earnings re78 (real earnings 1978), among received job training (average treatment effect treated, ATT).","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-exact-matching-with-low-dimensional-confounding","chapter":"Problem Set 4. Statistical modeling","heading":"2.1. (4 points) Exact matching with low-dimensional confounding","text":"part, assume three variables comprise sufficient adjustment set: race, married, nodegree. Use matchit argument method = \"exact\" conduct exact matching, matches two units identical along race, married, nodegree.Note: calling exact matching. thing previously called nonparametric estimation: make subgroups units identical along confounders, estimate treatment effect within subgroups, aggregate sample. using language matching parallel comes Question 4.many control units matched? many treated units?","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-effect-estimate","chapter":"Problem Set 4. Statistical modeling","heading":"2.2. (4 points) Effect estimate","text":"Estimate linear regression model using match data 2.1. Include treatment confounders 2.1 linear, additive specification. Weight weights matching.estimated effect job training earnings?","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-exact-matching-with-high-dimensional-confounding","chapter":"Problem Set 4. Statistical modeling","heading":"2.3. (4 points) Exact matching with high-dimensional confounding","text":"Now suppose adjustment set needs also include 1974 earnings, re74. adjustment set part race, married, nodegree, re74. Repeat exact matching .many control units matched? many treated units?","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-examining-matched-units","chapter":"Problem Set 4. Statistical modeling","heading":"2.4. (4 points) Examining matched units","text":"Look re74 values full data among matched units (need print output).\nExplain happened: different 1974 earnings matched vs unmatched cases?one way :Using function summary, look descriptive statistics re74 values full data.Using function summary, look descriptive statistics re74 values matched data. can get matched data using match.data function.can learn use summary function look descriptive statistics R data .notice? different values re74 full data versus matched data? Explain happened happened.","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-drawbacks-of-exact-matching","chapter":"Problem Set 4. Statistical modeling","heading":"2.5. (4 points) Drawbacks of exact matching","text":"Briefly interpret result 2.4: drawback using exact matching setting?","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"parametric-estimation","chapter":"Problem Set 4. Statistical modeling","heading":"3. Parametric estimation","text":"","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-outcome-modeling","chapter":"Problem Set 4. Statistical modeling","heading":"3.1. (5 points) Outcome modeling","text":"code , use lm() estimate Ordinary Least Squares regression future earnings re78 treatment treat, interacted confounders: race, married, nodegree, re74.Use model estimate average treatment effect among treated., shouldCreate two data frames\nfirst contain treated individuals (factual treatment 1)\nsecond contain treated individuals, treat set value 0\nfirst contain treated individuals (factual treatment 1)second contain treated individuals, treat set value 0Using model , predict expected outcomes two data frames created step 1.Report average treatment effect among treated.","code":"\noutcome_model <- lm(re78 ~ treat * (race + married + nodegree + re74),\n                    data = lalonde)"},{"path":"problem-set-4.-statistical-modeling.html","id":"points-treatment-modeling-creating-weights","chapter":"Problem Set 4. Statistical modeling","heading":"3.2. (5 points) Treatment modeling: Creating weights","text":"Note: part much help us. read provided understand, small part end. maximize learning-value--workload ratio problem.Using glm() , estimate probability treatment given confounders., using code , wepredict probability treat = 1generate propensity score unitcreate weight estimating Average Treatment Effect Treated, formula\\[w_i = \\frac{P(= 1\\mid \\vec{L} = \\vec\\ell_i)}{P(= a_i\\mid \\vec{L} = \\vec\\ell_i)}\\]Note: treated units, weight 1. untreated units, value varies.many treated units -heavily-weighted untreated unit represent? answer , want determine maximum weight amongst untreated individuals with_weight.","code":"\ntreatment_model <- glm(treat ~ race + married + nodegree + re74,\n                       data = lalonde,\n                       family = binomial)\nwith_weight <- lalonde %>%\n  # Create the propensity score\n  mutate(p_a_1 = predict(treatment_model, type = \"response\"),\n         pscore = case_when(treat == 1 ~ p_a_1,\n                            treat == 0 ~ 1 - p_a_1),\n         weight = p_a_1 / pscore)"},{"path":"problem-set-4.-statistical-modeling.html","id":"points-treatment-modeling-estimating-outcomes","chapter":"Problem Set 4. Statistical modeling","heading":"3.3. (5 points) Treatment modeling: Estimating outcomes","text":"Using with_weight object, take weighted means observed outcomes re78 weighted weight estimate average outcome treated units, weighted average outcome control units (weighted comparable treated units).Hint: want take weighted mean, grouped treatment status.","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"matching-without-requiring-exact-matches","chapter":"Problem Set 4. Statistical modeling","heading":"4. Matching without requiring exact matches","text":"hope class prepared learn new causal estimators, apply R, explain done. question chance practice! class discussed many matching approaches. question, choose approach. many correct answers, evaluated clarity code explanations.Task: Using matchit, conduct matching estimate ATT treat treatment sufficient adjustment set race, married, nodegree, re74.Use matchit, setting method, distance, arguments values choosing. requirements \nformula = treat ~ race + married + nodegree + re74\nestimand = \"ATT\"\nformula = treat ~ race + married + nodegree + re74estimand = \"ATT\"Create matched dataset using match.data()Estimate linear regression model using lm() formula re78 ~ treat + race + married + nodegree + re74 using matched data, weighted weights produced match.data().","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-conduct-the-matching","chapter":"Problem Set 4. Statistical modeling","heading":"4.1. (4 points) Conduct the matching","text":"space conduct matching. expect part R code chunk.","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-explain-your-choices","chapter":"Problem Set 4. Statistical modeling","heading":"4.2. (2 points) Explain your choices","text":"sentences, tell us matching approach chosen.","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-how-many-units-did-you-keep","chapter":"Problem Set 4. Statistical modeling","heading":"4.3. (2 points) How many units did you keep?","text":"Report number treated control units original data, many kept matching procedure.","code":""},{"path":"problem-set-4.-statistical-modeling.html","id":"points-report-your-causal-estimate","chapter":"Problem Set 4. Statistical modeling","heading":"4.4. (2 points) Report your causal estimate","text":"estimate average treatment effect treated? coefficient treat linear regression fit matched data.","code":""},{"path":"problem-set-5.-iv-rd.html","id":"problem-set-5.-iv-rd","chapter":"Problem Set 5. IV + RD","heading":"Problem Set 5. IV + RD","text":"Coming soon!","code":""},{"path":"problem-set-6.-did-synthetic-control.html","id":"problem-set-6.-did-synthetic-control","chapter":"Problem Set 6. DID + synthetic control","heading":"Problem Set 6. DID + synthetic control","text":"Coming soon!","code":""},{"path":"who-we-are.html","id":"who-we-are","chapter":"Who we are","heading":"Who we are","text":"","code":""},{"path":"who-we-are.html","id":"faculty","chapter":"Who we are","heading":"Faculty","text":"enjoy thinking problems goal discover interpretable structure underlies data generating process. includes problems areas causal discovery, graphical models, mixed membership models. many cases, methods tailored high-dimensional setting number variables considered may large compared number observed samples. applied interests vary generally social science related.study causal questions related inequality: people money others, disparities exist across social groups, intervene promote equality. Beyond causal inference, joys mine include hiking, surfing, oatmeal blueberries.","code":""},{"path":"who-we-are.html","id":"teaching-assistants","chapter":"Who we are","heading":"Teaching assistants","text":"’m currently working problems causal inference network interference. think causal inference really cool applications across many different fields. ’m generally interested applications public health, social welfare, social good. free time, enjoy singing, dancing, cooking, watching movies, traveling various theme parks.’m fascinated causal relationships enjoy exploring shape world. interests broadly centered area Computational Social Science, specifically focused can apply computational Machine Learning methods uncover estimate causal relationships. free time enjoy pretty much anything ’s active outdoors particularly enjoy playing tennis, kayaking, fishing (pro tips, let know).","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
