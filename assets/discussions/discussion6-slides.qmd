---
title: "Discussion. Parametric g-formula: Outcome modeling"
author: Cornell STSCI / INFO / ILRST 3900 \break Fall 2023 \break \href{https://causal3900.github.io/}{\textcolor{blue}{causal3900.github.io}}
date: 27 Sep 2023
format: beamer
date-format: DD MMM YYYY
header-includes:
  \usecolortheme{dove}
---

```{r, include = F}
knitr::opts_chunk$set(echo = T)
```

## Reminders and Announcements

- HW 3 due tomorrow (September 28) by 5pm
    - Submit a PDF from RMarkdown via Canvas
- Standard office hours
- Check Ed for HW questions!

## Agenda

- __Reminders and Announcements__
- __Icebreaker Activity__: Curse of dimensionality and possible issues with non-parametric estimation review
- __Group Exercise__: Parametric estimation (g-formula)
- __Homework Check-in and Questions__

## Icebreaker
Introduce yourselves!

1. What is the curse of dimensionality?
2. How does this relate to non-parametric estimation?
3. How do we know when non-parametric estimation might be impossible?
    - Feel free to look at yesterdayâ€™s slides.

## Where lecture ended

\centering

```{=tex}
\begin{tikzpicture}[x = 1in, y = .4in]
\node (a) at (0,0) {$A$};
\node (y) at (1,0) {$Y$};
\node (l1) at (-1,2) {$L_1$};
\node (l2) at (-1,1.66) {$L_2$};
\node (l3) at (-1,1.33) {$L_3$};
\node (l4) at (-1,1) {$L_4$};
\node (l5) at (-1,.66) {$L_5$};
\node (l6) at (-1,.33) {$L_6$};
\node (l7) at (-1,0) {$L_7$};
\draw[->, thick] (l1) -- (a);
\draw[->, thick] (l2) -- (a);
\draw[->, thick] (l3) -- (a);
\draw[->, thick] (l4) -- (a);
\draw[->, thick] (l5) -- (a);
\draw[->, thick] (l6) -- (a);
\draw[->, thick] (l7) -- (a);
\draw[->, thick] (a) -- (y);
\draw[->, thick] (l1) to[bend left] (y);
\draw[->, thick] (l2) to[bend left] (y);
\draw[->, thick] (l3) to[bend left] (y);
\draw[->, thick] (l4) to[bend left] (y);
\draw[->, thick] (l5) to[bend left] (y);
\draw[->, thick] (l6) to[bend left] (y);
\draw[->, thick] (l7) to[bend left] (y);
\node[anchor = north, align = center, font = \footnotesize] at (a.south) {College\\Degree\\by Age 25};
\node[anchor = north, align = center, font = \footnotesize] at (y.south) {Spouse\\at Age 35\\Has Degree};
\node[anchor = east, align = center, font = \footnotesize] at (l1.west) {Sex};
\node[anchor = east, align = center, font = \footnotesize] at (l2.west) {Race};
\node[anchor = east, align = center, font = \footnotesize] at (l3.west) {Mom Education};
\node[anchor = east, align = center, font = \footnotesize] at (l4.west) {Dad Education};
\node[anchor = east, align = center, font = \footnotesize] at (l5.west) {Income};
\node[anchor = east, align = center, font = \footnotesize] at (l6.west) {Wealth};
\node[anchor = east, align = center, font = \footnotesize] at (l7.west) {Test Percentile};
\end{tikzpicture}
```
\huge

**100%** of the sample

\normalsize

is in a subgroup with either 0 treated or 0 untreated units

## Setup

Follow the instructions on Ed to download the data!

```{r, include = F, eval = T}
library(tidyverse)
d <- readRDS("d.RDS")
```

## Statistical modeling

Under exchangeability, $$E\left(Y^a\mid\vec{L} = \vec\ell\right) = E\left(Y\mid A = a, \vec{L} = \vec\ell\right)$$

To estimate, we have been taking the subgroup mean $$\hat{E}(Y\mid A = a, \vec{L} = \vec\ell) = \frac{1}{n_{a,\vec\ell}}\sum_{i:A_i=a,\vec{L}_i=\vec\ell} Y_i$$ When subgroups are empty, we need a model. Example:

$$\hat{E}\left(Y\mid A = a, \vec{L} = \vec\ell\right) = \hat\alpha + A\hat\beta + \vec{L}'\hat{\vec\gamma} + A\vec{L}'\hat{\vec\eta}$$

## Parametric g-formula: Outcome modeling

1.  Learn a model to predict $Y$ given $\{A,\vec{L}\}$
2.  For each $i$, predict
    -   $\{A = 1,\vec{L} = \vec\ell_i\}$, the conditional average outcome under treatment
    -   $\{A = 0, \vec{L} = \vec\ell_i\}$, the conditional average outcome under control
3.  Take the difference for each unit
4.  Average over the units

## G-formula: Data example

Estimate a model based on the true data

```{r, echo=FALSE}
d |>
  select(a:race) |>
  head(10) |>
  arrange(a)
```

## Predict values - control

Predict the counterfactuals when everybody is in the control group
```{r, echo=FALSE}
d |>
  select(a:race, -y) |>
  head(10) |>
  arrange(a) |>
  mutate(a = "no_college")
```

## Predict values - treatment

Predict the counterfactuals when everybody is in the treatment group
```{r, echo=FALSE}
d |>
  select(a:race, -y) |>
  head(10) |>
  arrange(a) |>
  mutate(a = "college")
```

## 1. Learn a model to predict $Y$ given $\{A,\vec{L}\}$

```{r}
fit <- lm(y ~ a + sex + race + mom_educ + dad_educ + 
                   log_parent_income + 
                   log_parent_wealth + 
                   test_percentile,
          data = d)
```

## 2. Predict conditional average potential outcomes for every unit

```{r}
conditional_average_outcomes <- d %>%
  mutate(yhat1 = predict(fit, 
                         newdata = d %>% 
                           mutate(a = "college")),
         yhat0 = predict(fit, 
                         newdata = d %>% 
                           mutate(a = "no_college")))
```

## 3. Difference to estimate conditional average effects

```{r}
conditional_average_effects <- 
  conditional_average_outcomes %>%
  mutate(effect = yhat1 - yhat0)
```

## 4. Average over units

```{r}
conditional_average_effects %>%
  select(yhat1, yhat0, effect) %>%
  summarize_all(.funs = mean)
```

## Recap. Parametric g-formula: Outcome modeling

1.  Learn a model to predict $Y$ given $\{A,\vec{L}\}$
2.  For each $i$, predict
    -   $\{A = 1,\vec{L} = \vec\ell_i\}$, the conditional average outcome under treatment
    -   $\{A = 0, \vec{L} = \vec\ell_i\}$, the conditional average outcome under control
3.  Take the difference for each unit
4.  Average over the units

## Extension 1: Conditional average effects

Modify the procedure above to estimate the average effect in subgroups defined by mom's education:

1.  those with `sex == Male`
2.  those with `sex == Female`

If you finish, choose a subgroup of interest to you and summarize.

. . .

One way to code it:

```{r}
conditional_average_effects %>%
  group_by(sex) %>%
  select(sex, yhat0,yhat1,effect) %>%
  summarize_all(.funs = mean)
```

## Extension 2: Logistic regression

In groups: Repeat the steps above with logistic regression

$$\text{log}\left(\frac{\hat{P}\left(Y\mid A = a, \vec{L} = \vec\ell\right)}{1 - \hat{P}\left(Y\mid A = a, \vec{L} = \vec\ell\right)}\right) = \hat\alpha + A\hat\beta + \vec{L}'\hat{\vec\gamma} + A\vec{L}'\hat{\vec\eta}$$ Helpful hints:

-   read about using `glm()` to estimate logistic regression
-   when using `predict()`, search to find out how to predict probabilities

## Extension: Logistic regression

Fit a model

```{r}
fit <- glm(y ~ a*(sex + race + mom_educ + dad_educ + 
                    log_parent_income + 
                    log_parent_wealth + 
                    test_percentile),
           data = d,
           family = binomial)
```

## Extension: Logistic regression

Predict and summarize to estimate the average effect

\footnotesize
```{r}
d %>%
  mutate(yhat1 = predict(fit, 
                         newdata = d %>% 
                           mutate(a = "college"), 
                         type = "response"),
         yhat0 = predict(fit, 
                         newdata = d %>% 
                           mutate(a = "no_college"), 
                         type = "response"),
         effect = yhat1 - yhat0) %>%
  select(yhat1,yhat0,effect) %>%
  summarize_all(.funs = mean)
```

## Recap. Parametric g-formula: Outcome modeling

1.  Learn a model to predict $Y$ given $\{A,\vec{L}\}$
2.  For each $i$, predict
    -   $\{A = 1,\vec{L} = \vec\ell_i\}$, the conditional average outcome under treatment
    -   $\{A = 0, \vec{L} = \vec\ell_i\}$, the conditional average outcome under control
3.  Take the difference for each unit
4.  Average over the units
